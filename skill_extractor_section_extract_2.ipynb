{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMJfuX2nK1JsAae9Q/bbuV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schmcklr/skill_extractor/blob/main/skill_extractor_section_extract_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2:** Skill Section Extraction and Preprocessing\n",
        "\n",
        "This specialized program systematically extracts the qualification section from english job ads by scouring the HTML source code. It identifies key phrases and specific patterns, derived from the analysis of over 1500 job ads. The extracted qualifications, along with the remaining job ad data, are compiled in a data frame and exported to an Excel file for further analysis. Ads where the qualification section couldn't be extracted are automatically excluded from the export\n"
      ],
      "metadata": {
        "id": "1jpJ4wf6tSh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load preprocessed data\n",
        "*   Import of translated job advertisements ([Part 1](https://github.com/schmcklr/skill_extractor/blob/main/skill_extractor_preprocessing_1.ipynb))\n"
      ],
      "metadata": {
        "id": "soa-t2_96UwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Fetching raw data\n",
        "workbook = 'https://github.com/schmcklr/skill_extractor/blob/main/job_data/job_data_preprocessed_translated.xlsx?raw=true'\n",
        "\n",
        "# Import of tabs\n",
        "job_data = pd.read_excel(workbook, sheet_name=\"Sheet1\")"
      ],
      "metadata": {
        "id": "2M-ZwW1AfHtg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Function Definitions"
      ],
      "metadata": {
        "id": "K2XUY2Qk6n7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   extract_lists_and_paragraphs\n",
        "*   filter_duplicates\n",
        "*   filter_key_phrases\n",
        "*   check_stop_phrases_element\n",
        "*   truncate_text_on_stopphrase  \n",
        "*   extract_qualification_section\n"
      ],
      "metadata": {
        "id": "3pgsBbvp7vOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Filter duplicates"
      ],
      "metadata": {
        "id": "b03oosFs66dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter duplicated sentences\n",
        "def filter_duplicates(sentences):\n",
        "    filtered_sentences = []\n",
        "    sentences = sorted(sentences, key=len, reverse=True)\n",
        "    for sentence in sentences:\n",
        "        if all(sentence not in other_sentence for other_sentence in filtered_sentences):\n",
        "            filtered_sentences.append(sentence)\n",
        "    return filtered_sentences"
      ],
      "metadata": {
        "id": "wjjenLLNfF9C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Filter key phrases"
      ],
      "metadata": {
        "id": "-rfE_TrK69oQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter key phrases by removing key_phrases which are in list key_phrases_exact_match\n",
        "def filter_key_phrases(key_phrases, key_phrases_exact_match):\n",
        "    filtered_phrases = []\n",
        "    for phrase in key_phrases:\n",
        "        if not any(phrase == match for match in key_phrases_exact_match):\n",
        "            filtered_phrases.append(phrase)\n",
        "    return filtered_phrases"
      ],
      "metadata": {
        "id": "oWW0Afu-7CMk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Stopphrase checking"
      ],
      "metadata": {
        "id": "VDEhGQHckCQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Element\n",
        "# Stop extracting if one of the stopphrases has been dedected\n",
        "def check_stop_phrases_element(next_element):\n",
        "  # Clean the text by removing non-alphanumeric characters and whitespace characters\n",
        "  if next_element and next_element.string != None:\n",
        "    cleaned_element_text = re.sub(r'[^\\w\\s]', '', next_element.string.strip())\n",
        "\n",
        "  # Detect stop_phrases within the first 45 characters\n",
        "  if any(stop_phrase in ' '.join(next_element.text.split()[:45]) for stop_phrase in stop_phrases):\n",
        "    return True\n",
        "    # Only used for developing context\n",
        "    #matched_phrases = [stop_phrase for stop_phrase in stop_phrases if stop_phrase in ' '.join(next_element.text.split()[:50])]\n",
        "    #if matched_phrases:\n",
        "      #print('Stopphrase detected:', matched_phrases[0])\n",
        "\n",
        "  # Detect stop_phrases_exact_match\n",
        "  if next_element and next_element.string != None and any(stop_phrase_exact_match == cleaned_element_text for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "    return True\n",
        "\n",
        "  return False"
      ],
      "metadata": {
        "id": "feEIUHeTkCAP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Element text\n",
        "# Stop extracting if one of the stopphrases has been dedected\n",
        "def check_stop_phrases_element_text(element_text):\n",
        "    cleaned_element_text = re.sub(r'[^\\w\\s]', '', element_text)\n",
        "\n",
        "    if any(stop_phrase in element_text for stop_phrase in stop_phrases):\n",
        "        return True\n",
        "\n",
        "    if cleaned_element_text is not None and any(stop_phrase_exact_match == cleaned_element_text for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "        return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "NzZMtaI56740"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4 Extract section until stopphrase occurs"
      ],
      "metadata": {
        "id": "9ULQTUkKtG-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_text_on_stopphrase(element):\n",
        "    text = element.text\n",
        "\n",
        "    min_index = len(text)  # Index der kürzesten Stopphrase im Text\n",
        "    selected_stop_phrase = None  # Ausgewählte Stopphrase zum Abschneiden\n",
        "\n",
        "    for stop_phrase in stop_phrases:\n",
        "        index = text.find(stop_phrase)\n",
        "        if index != -1 and index < min_index:\n",
        "            min_index = index\n",
        "            selected_stop_phrase = stop_phrase\n",
        "\n",
        "    if selected_stop_phrase:\n",
        "        truncated_text = text[:min_index].strip()\n",
        "        return truncated_text\n",
        "    else:\n",
        "        return text"
      ],
      "metadata": {
        "id": "vYHDJ92TtE1d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5 Filter and clean qualification list"
      ],
      "metadata": {
        "id": "J1UU5BUG1AK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_and_clean_qualifications(qualifications):\n",
        "    filtered_qualifications = []\n",
        "    for qualification in qualifications:\n",
        "        clean_qualification = \"\".join(char for char in qualification if char.isalpha() or char.isspace())\n",
        "        if clean_qualification and clean_qualification not in key_phrases:\n",
        "            filtered_qualifications.append(qualification)\n",
        "    return filtered_qualifications"
      ],
      "metadata": {
        "id": "fUEnHzB11Ld6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6 Definition of lists\n",
        "\n",
        "\n",
        "*   **key_phrases** (for identifying the Skills section)\n",
        "\n",
        "*   **key_phrases_exact_match** (key phrases that should only be recognized when they are within a separate tag element)\n",
        "*   **key_phrases_without_exact_match** (only key phrases which are not in the key_phrases_exact_match)\n",
        "*   **stop_phrases** (phrases that, upon occurrence, should halt the extraction process)\n",
        "*   **stop_phrases_exact_match** (stop phrases that should only be recognized when they are within a separate tag element)\n",
        "*   **stop_words** (words that should be removed from the text)\n",
        "\n"
      ],
      "metadata": {
        "id": "6bgnNl1g0mwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Key Phrases\n",
        "key_phrases = [\n",
        "    'required experience & competencies', 'who we are looking for', 'requirements', 'competencies', 'required skills', 'technical skills', 'education', 'skills required', 'common core skills', 'qualifikationen', 'profile', 'have knowledge in',\n",
        "    'minimum knowledge and skills required', 'was sie mitbringen', 'language skills', 'desired/plus', 'language','desirable attributes', 'skills and experience', 'what we expect from you',\n",
        "    'required/must have', 'core competencies', 'qualifications required', 'essential qualifications', 'position criteria', 'complément du descriptif', 'compétences requises',\n",
        "    'profile description', \"you're at the right place, if\", 'skills and competencies', 'competencies required', 'professional qualification', 'soft skills',\n",
        "    'we are looking for people, who are', 'qualifications', 'your background', 'must have', 'nice to have', 'your profile', 'compétences', 'votre profil', 'your skills', 'you...', 'you:',\n",
        "    'languages', 'personal abilities', 'required competencies', 'compétences requises', 'profil candidat', \"le plus de l'offre\", '候选人能力&amp;要求', 'experience and education',\n",
        "    'your qualities', 'what will make you successful', \"who we're looking for\", 'basisqualifikationen', \"what you'll bring to us\", \"dein profil\", 'what we are looking for',\n",
        "    'skills', 'knowledge', 'your strengths', 'required technical', 'professional expertise', 'preferred technical and professional expertise', 'you bring that with', 'what you need is',\n",
        "    'an ideal candidate will be', 'minimum qualifications', 'preferred qualifications', 'basic qualifications', 'your qualifications', 'about you', 'profil', 'your personality','your qualification', 'what you need to have',\n",
        "    'who are you?', 'ihr profil', 'do i qualify?', 'requisitos', 'they fit us.', \"what you’ll need\", 'come as you are', 'your story', 'are you a fit?', 'we’re looking for people who', 'what are we looking for',\n",
        "    '· you are in your last semester of a bachelor’s or master’s program or have graduated less than six months ago', 'job requirements', 'required skills:', 'preferred skills:',\n",
        "    'do you have what it takes to be the field sales manager', 'you', 'who are we looking for', 'the perfect candidate', 'qualification','experience & key skills', 'studied:', 'skills to create thrills',\n",
        "    'das bringen sie mit', 'candidate:', 'skills & qualifications', 'for people with many qualities', 'who you are', 'required profile', 'we are looking for people who', 'about the candidate',\n",
        "    'we are seeking highly motivated individuals who meet the following criteria', 'qualifications and skills', 'you are…', \"if you’re a good fit, you’ll have\", \"if you’re a really good fit, you’ll have\",\n",
        "    'am i a perfect match', 'to qualify for the role you must have', 'education and qualifications / skills and competencies', 'is it you, we are looking for', 'main competence requirement',\n",
        "    'expérience requise et formation', 'expérience requise et formation', 'experience', 'personal competencies', 'digital competencies', 'managerial competencies',\n",
        "    'required education', 'we are looking for someone who has', 'will be an advantage if the candidate has', 'you score with us', \"what you'll bring to us\", 'expérience requise et formation',\n",
        "    'you are best equipped for this task if you have', 'we look for', 'connaissances/expérience', 'do you have what it takes', 'profil recherché', 'personal skills', 'you are...','technical knowledge',\n",
        "    'to fit in the role, you also have', 'requirement', 'what we expect', 'your profile  ready to step on the gas', \"what we’re looking for\", 'formula for success', 'seeked profile',\n",
        "    'what will you bring to hp?', 'this is you', 'required skills', 'preferred skills', ' you are an accounting professional', 'experience and specific knowledge', \"are you the process innovator we're looking for?\",\n",
        "    'your profile  B', 'you bring that with –f ä', 'so you score with us', \"what you'll need\", 'wanted profile', 'your background looks like', 'bringing ', 'what we are expecting',\n",
        "    'this scores with us', 'in this you are a specialist', 'you can see you in this function when you', 'what you need', 'job skills and knowledge required', \"here's what we require\",\n",
        "    \"to be successful in this role you will need the following\", 'who you are?', \"you'll be the right fit if you\", \"you`ll be the right fit if you have\", 'what will you bring',\n",
        "    \"you’ll need to have\", \"we’d love to see\", \"In this you are a specialist\", \"this is what you`ll bring to us\", \"we're looking for people who\", \"am i qualified\", \"you'll need to have\",\n",
        "    \"you specialist\", \"expected skills\", \"you bring\", \"you ...\", \"the ideal candidate will meet the following requirements\", \"what we're looking for\", 'professional skills', 'specific competencies',\n",
        "    \"anforderungsprofil\", \"your skills  talents\", \"therefore fit us\", \"what else will make you successful\", \"the following requirement profile bring with\", \"this is the case with\", 'stating the job reference',\n",
        "    'essential experience', \"desirable experience\", \"we'd love to see\", \"requisitos\", 'you are a perfect fit for us if you', 'anforderungen/ kenntnisse', 'requirements', 'key skills, capabilities',\n",
        "    'what can you contribute', \"a motivated enthusiastic personality with a good understanding of the relationships between the business and the it your way of working can be described as independent responsible and solutionoriented furthermore you have the following background\",\n",
        "    'successful applicants will likely possess most of these', 'what do you bring with', 'required technical and professional expertise', 'what will make you successful', 'qualifikationen', 'desired',\n",
        "    'personality', 'knowledge & experience', 'this is what your background looks like', 'you have', 'technical and professional skills', 'behavioural competency required', 'competency', 'behaviour',\n",
        "    ' personal competencies', 'you also have the following qualities', 'essential skills', 'personal attributes', 'preferred qualifications', 'additional important requirements', 'role competencies',\n",
        "    'minimum education requirements', 'personal competencies', 'key skills', 'you are best equipped for this work, if you', 'target disciplines and special skills', 'to fit in the role, you also',\n",
        "    'further skills', 'it skills', 'language skills', 'studies', 'studied', 'minimum education and experience', 'candidate profile', 'ideal candidate', 'technical requirements', 'further requirements',\n",
        "    'desired requirements', 'technical  professional knowledge', 'working experience', 'preferred tech and prof experience', 'what were looking for', 'to be eligible', 'you need',\n",
        "    'you are interested in or have knowledge in', 'knowledge/technical skills', 'what skills/experience we are looking for', 'how can you make a difference', 'desired  skills & exp erience',\n",
        "    'experience & skills', 'skills &amp; exp', 'desired skills', 'skills / experience', 'preferred requirements', 'required experience','your heroic skills', 'requirements profile',\n",
        "    'requisite skills & experience', 'technical competencies', 'behavioural competencies', 'you are interested in or have knowledge in :', 'knowledge  knowledge  experiences', 'you preferably have',\n",
        "    'required professional and technical expertise', \"to summarise, we're looking for someone with\", 'what we look for', 'besides a technical strong basis we are looking for people who',\n",
        "    'monitoring the administrative organization and the internal controls', 'you have a toyota dna, this means you', 'entry requirements', 'you should apply if you are', 'desired skills & experience',\n",
        "    'education and work experience', \"you are an m/f/x that has proven business judgement and you have a passion for what technology and data science can do. you love working with customers, you aspire to be a domain expert one day in either an entire industry or a process and you get excited when you are influencing change to executives through market-leading saas technology.\",\n",
        "    'required backround and experience', 'educational qualification', 'work experience & qualifications', 'key requirements/experience', 'what you need to succeed', 'qualifikationen und erfahrung', 'valuable skills',\n",
        "    'preferred work experience', 'we expect you to', 'attitude is important! we are looking for people, who are', 'with potential value', 'your skills', 'required', 'desired', 'base compentencies',\n",
        "    'you are looking for an opportunity to accelerate your career in financial management at international level and emerge as a financial leader within a dynamic and challenging organization',\n",
        "    'plus, you fulfill the following hard fact based criteria', 'and you fully agree to these statements', '候选人能力&要求', 'requirements:', 'education', ', schedules, and manage customer expectations',\n",
        "    'experience/knowledge required', 'essential', 'desirable', 'required languages', 'personal required skills', 'skills and knowledge', 'relevant work experience', '2.    knowledge/experience',\n",
        "    'education, experience and skills', 'key success criteria', 'do you have what it takes to be the field sales manager?', 'you are best equipped for this task if you', ' your profile',\n",
        "    '- you have a degree in computer science, business informatics or a comparable education', '- you are passionate about the daimlers concept of innovative payment solutions',\n",
        "    'technical & professional knowledge', 'you are skilled', 'who can apply for the acaddemict business & functional analyst program?', 'skills and qualifications', 'desired experience',\n",
        "    'student profile', 'requirements / knowledge / experience', 'expected profile', 'in order to apply for the graduate programme, you must have', 'profil :',\n",
        "    '##master in engineering, or business administration and at least 3 years of experiences in digital (insurance or web/e-commerce) as a business analyst',\n",
        "    'you have successfully completed your studies in computer science, business informatics, business administration, economics or industrial engineering.handy tools',\n",
        "    \"technical business/data analyst for change initiatives for allianzgi's alternatives investment platform\", 'your skills &amp; talents...', 'hard skills',\n",
        "    'university degree (law / business preferred)', '##support development and continuous improvement of required processes', 'what is your educational background',\n",
        "    'requirements / knowledge / experience< /b', 'education and experience', 'applying creative methods to consume data from is/it sources or move data between is/it solutions in the ecosystem.',\n",
        "    'knowledge / knowledge / experiences', 'preferred skills (good to have)', 'languages required', 'this role requires', 'education and professional background',\n",
        "    'experience in sap functional area as', 'capabilities in new technologies', 'your strengths', 'level of diploma',\n",
        "    'we offer the opportunity to develop a fascinating career in exchange for a few requirements', 'high it affinity'\n",
        "    ]\n",
        "\n",
        "# Key Phrases exact match\n",
        "key_phrases_exact_match = ['you...', 'you:', 'your strengths', 'about you', 'you', 'profil', 'who are', 'ihr profil', 'do i qualify?', 'requisitos', 'they fit us.','your story','skills',\n",
        "                           'are you a fit?', 'candidate:', 'who you are','you are…', 'you are...', 'your skills', 'requirement', 'experience', 'this is you', 'bringing ', 'you specialist',\n",
        "                           \"you ...\", \"we look for\", 'you have', 'education', 'behaviour', 'profile', 'desired','studies', 'it skills', 'erience', 'required', 'essential', 'desirable',\n",
        "                           'knowledge', 'and:']\n",
        "\n",
        "# Key Phrases without exact match\n",
        "key_phrases_without_exact_match = filter_key_phrases(key_phrases, key_phrases_exact_match)\n",
        "\n",
        "# Stop phrases\n",
        "stop_phrases = ['audit planning', 'pwc', 'impact/scope', 'offers that convince me', 'what do we offer you', 'additional information', 'we...', 'ubisoft',\n",
        "                'you can look forward to', 'airbus', 'what you’ll get in return', 'send us your application', 'zusätzliche informationen', 'allianz is', 'why amazon',\n",
        "                'airbus', 'candidates who are considered for a position', 'co-ordinating it cover', 'apply today', 'thanks for taking the time', 'application procedure', 'cover letter',\n",
        "                'in order to apply', 'please note that', 'mars', 'all applications will be reviewed', 'please send your application to', 'volvo group', 'contract:',\n",
        "                'stipend and benefits', 'documents to your application', 'your cv in english', 'application and assessment process', 'full-time job', 'reference code','ibm is committed',\n",
        "                'your tasks will be', 'are you interested?', 'tasks in detail', 'studies/training', 'start contract date', 'we offer', 'about us ', 'unibail', 'qualified applicants will receive consideration',\n",
        "                'provide proper reporting', 'can apply', 'huntsville', 'work with external resource', 'you are not a regular helpdesk', 'perks at work', 'about zalando', \"zalando is europe’s leading\", 'internal tech academy',\n",
        "                'further information for your application', 'bmw group', 'experience what moves us', 'contact our recruiting team', 'security/export control statement', 'our offer',\n",
        "                'working conditions', 'if you share our values and vision', 'more opportunities for your development', 'student programs team', 'please no phone calls', 'hat we offer',\n",
        "                'additional information', 'order to be eligible for an internship', 'key dates:', 'what will you work on', 'why netsuite', 'novutech in a nutshell', \"#1 cloud-based\",\n",
        "                \"what's in it for you\", 'place of employment', 'you are going to bring', 'together we will rethink', 'are you ready for a new challenge', 'the application of', 'general function',\n",
        "                'management system provides', 'deloitte-recruiting team', 'what are the central tasks', 'new york it', 'new yorkers offers', \"you'll be working within an audit team\",\n",
        "                'interested?', 'best business school in the world', 'siehe job description', 'graduates working in project controls', \"pour l'analyse de données\", 'in order to structure our',\n",
        "                'recruiting or consulting agency', 'key figures', 'production sites', 'deine benefits', 'you will prepare market', 'transfer pricing structures', 'your benefit',\n",
        "                'application configuration and support','please note', 'we advise corporates', 'seller support center', 'configure and support', 'diversity and inclusion', 'the nestlé group',\n",
        "                \"please don't hesitate and apply\", 'lufthansaglobal business services gmbh', 'messier-dowty', ' canadian controlled', 'equal opportunity employer',\n",
        "                'tasks and responsibilities', 'coach and mentor', 'scor global life americas', 'we are looking forward to your application', 'you make the impossible possible',\n",
        "                'takes responsibility for achieving', 'responsibility for achieving', 'accountabilitytakes', 'permanent job', 'contract :', 'the internship stipend',\n",
        "                'a temporary position', 'stipend and benefits', 'upload your cv', 'salary', 'you are offered', 'please apply', 'approve monthly/weekly delivery',\n",
        "                'via lufthansa global business services', 'at criteo', 'nestlé is the largest food', 'your responsibilities', 'use analytics', 'appointment date', ' please send',\n",
        "                'application period', 'protecting your privacy', 'singapore r&d office', 'belonging to toyota', 'start -up date', 'at allianz', 'position based in', 'category :',\n",
        "                'with us you are part', 'you have the chance', 'coffee and water', 'our company pension', 'nike european headquarters', 'compelling marketing copy', 'flexible working times',\n",
        "                'tech-unicorns in the world', 'why us?', 'flat hierarchies', 'scholarship', 'terms & conditions', 'position summary','our tech department', 'benefits', 'grow together',\n",
        "                'free sports', 'about the application process', 'dynamic and international working', 'deliver accurate and timely', 'your next career step', 'analyze, document',\n",
        "                'remember to attach', 'actively shape', 'the department', 'do we want to achieve', 'new yorkers', 'part of our team', 'responsibility and decision-making authority',\n",
        "                'a combination of personal', 'swts manufactures', 'exellys', 'duration: 6 months full-time', 'what’s in it for you', 'accelerate your technical capabilities',\n",
        "                'contact info', 'duration:', 'mobile al', 'note to students', 'allianz group', 'vmware is committed', 'vmware company overview', 'ntry level', 'ibm services is a team',\n",
        "                'about business unit', 'about ses', 'join seb global services', 'to be a part of international company', 'amazon is an equal opportunities'\n",
        "                ]\n",
        "\n",
        "# Stop words\n",
        "stop_words = ['required:', 'desired:', 'required', 'desired', 'required skills:', 'desired characteristics/skills', 'functional skills:', 'you are:', 'is it you, we are looking for?',\n",
        "              'https://www.bankaustria.at/karriere.jsp', 'knowledge/technical skills', 'what skills/experience we are looking for:', 'licenses/certifications/other',\n",
        "              'entry level', \"ideally, you’ll also have\", 'as per job description.', \"what you'll need\", 'we are willing to cover 2 positions:', 'work experience & qualifications:',\n",
        "              'to qualify for the position(s), you possess the following qualities:', 'who are you?', 'professional qualification routes', 'new graduate',\n",
        "              'educational qualifications:', 'what kind of candidate are we looking for?', 'we are looking for someone that shares the same values as our team:', 'local job requirements',\n",
        "              \"https://www.be-lufthansa.com/de/faqs-be-frifthansa/lufthansa/internship degree work/\", 'you are offered', 'via lufthansa global', 'department description:',\n",
        "              '##support development and continuous improvement of required processes', 'category :', '!our', 'experience :', 'general requirements:', 'preferred skills:',\n",
        "              'profile preferred qualifications', 'profile key requirements']\n",
        "\n",
        "# Stop phrases exact match\n",
        "stop_phrases_exact_match = ['we',  'we offer', 'training and resources', 'location', 'entry level', 'ibm',  'ey', 'deloitte','contract','lufthansa', 'responsibilities',\n",
        "                            'application support', 'basf', 'how to apply']"
      ],
      "metadata": {
        "id": "Mz4w2xVv0lNl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6 Main function for skill section extraction"
      ],
      "metadata": {
        "id": "2cWuC1Im7GVN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nrFa94InE3gz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Identifying key phrases and extracting the qualification section\n",
        "def extract_qualification_section(df_row):\n",
        "    # Tracks if p or ul element has been found\n",
        "    p_ul_found = False\n",
        "    # Tracks if key_phrase has been found\n",
        "    key_phrase_found = False\n",
        "    # Tracks if a key_phrase has been found\n",
        "    found = False\n",
        "    # Tracks if a section has been found\n",
        "    section_found = False\n",
        "    # Tracks if a 'tr' HTML object has been found\n",
        "    tr_found = False\n",
        "\n",
        "    # Initialize list to store qualifications\n",
        "    qualifications = []\n",
        "\n",
        "    # Checking if df_row is of type string\n",
        "    if type(df_row) != str:\n",
        "      print('Row is not of type string')\n",
        "      return('Skills can not be detected!')\n",
        "    else:\n",
        "       df_row = df_row.lower()\n",
        "\n",
        "    # Creates a BeautifulSoup object by passing 'df_row' and specifying the parser as 'html.parser'\n",
        "    soup = BeautifulSoup(df_row, 'html.parser')\n",
        "\n",
        "    # Iterate through the list of key_phrases\n",
        "    for key_phrase in key_phrases:\n",
        "\n",
        "      # Reset boolean variables\n",
        "      found = False\n",
        "      p_ul_found = False\n",
        "\n",
        "      # Searches for all specified elements and verifies if a keyphrase is present between the specified element and the following element\n",
        "      # Case that key_phrase is between a div tag and another tag\n",
        "      div_tags = soup.find_all('div')\n",
        "      for i in range(len(div_tags)):\n",
        "        div_element = div_tags[i].find_next()\n",
        "        if div_element and div_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', div_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = div_tags[i]\n",
        "            break\n",
        "          if div_element is not None:\n",
        "            div_element = div_element.find_next()\n",
        "\n",
        "      # Case that key_phrase is between a b tag and another tag\n",
        "      b_tags = soup.find_all('b')\n",
        "      for i in range(len(b_tags)):\n",
        "        b_element = b_tags[i].find_next()\n",
        "        if b_element and b_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', b_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = b_tags[i]\n",
        "            break\n",
        "          if b_element is not None:\n",
        "            b_element = b_element.find_next()\n",
        "\n",
        "      # Case that key_phrase is between a br tag and another tag\n",
        "      # Searches for all defined elements and checks if keyphrase is in the text is between the defined element and the following element\n",
        "      br_tags = soup.find_all('br')\n",
        "      for i in range(len(br_tags)):\n",
        "        br_element = br_tags[i].find_next()\n",
        "        if br_element and br_element.previous_sibling:\n",
        "          previous_sibling_text = br_element.previous_sibling.text\n",
        "          if isinstance(previous_sibling_text, str):\n",
        "              previous_sibling_text = re.sub(r'[^\\w\\s]', '', previous_sibling_text).strip()\n",
        "              # Removing non-alphanumeric characters and whitespace\n",
        "              # Case 1:\n",
        "              if (re.sub(r'[^\\w\\s]', '', key_phrase).strip() in previous_sibling_text and key_phrase in key_phrases_without_exact_match and len(previous_sibling_text.split()) < 6) or (re.sub(r'[^\\w\\s]', '', key_phrase).strip() == previous_sibling_text):\n",
        "                  found = True\n",
        "                  key_phrase_found = True\n",
        "                  element = br_tags[i]\n",
        "                  break\n",
        "              # Case 2:\n",
        "              elif re.sub(r'[^\\w\\s]', '', key_phrase).strip() == previous_sibling_text:\n",
        "                  found = True\n",
        "                  key_phrase_found = True\n",
        "                  element = br_tags[i]\n",
        "                  break\n",
        "          if br_element is not None:\n",
        "            br_element = br_element.find_next()\n",
        "\n",
        "      # Case that key_phrase is between a strong tag and another tag\n",
        "      strong_tags = soup.find_all('strong')\n",
        "      for i in range(len(strong_tags)):\n",
        "        strong_element = strong_tags[i].find_next()\n",
        "        if strong_element and strong_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', strong_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = strong_tags[i]\n",
        "            break\n",
        "          if strong_element is not None:\n",
        "            strong_element = strong_element.find_next()\n",
        "\n",
        "      # Case that key_phrase is between a span tag and another tag\n",
        "      span_tags = soup.find_all('span')\n",
        "      for i in range(len(span_tags)):\n",
        "        span_element = span_tags[i].find_next()\n",
        "        if span_element and span_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', span_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = span_tags[i]\n",
        "            break\n",
        "          if span_element is not None:\n",
        "            span_element = span_element.find_next()\n",
        "\n",
        "\n",
        "      # Case that key_phrase is between a li tag and another tag\n",
        "      li_tags = soup.find_all('li')\n",
        "      for i in range(len(li_tags)):\n",
        "        li_element = li_tags[i].find_next()\n",
        "        if li_element and li_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', li_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = li_tags[i]\n",
        "            break\n",
        "          if li_element is not None:\n",
        "            li_element = li_element.find_next()\n",
        "\n",
        "\n",
        "\n",
        "      # Case that key_phrase is between a end tag and another tag\n",
        "      tags = soup.find_all()\n",
        "      for i in range(len(tags) - 1):\n",
        "          # Check if the current tag is an end tag and the next tag is a start tag\n",
        "          if tags[i] and tags[i + 1]:\n",
        "              if tags[i].name and tags[i + 1].name and tags[i].name != tags[i + 1].name:\n",
        "                  next_sibling = tags[i].next_sibling\n",
        "                  if next_sibling and hasattr(next_sibling, 'text'):\n",
        "                      next_sibling_text = next_sibling.text.strip()\n",
        "                      if next_sibling_text:\n",
        "                          stripped_text = (re.sub(r'[^\\w\\s]', '', next_sibling_text))\n",
        "                          if re.sub(r'[^\\w\\s]', '', key_phrase) == stripped_text:\n",
        "                              found = True\n",
        "                              key_phrase_found = True\n",
        "                              element = next_sibling\n",
        "                              break\n",
        "\n",
        "      # Looks for occurrences where the keyphrase appears between a <p> element and a subsequent <br> element\n",
        "      pattern = rf'<p>\\s*{re.escape(key_phrase)}\\s*(:\\s*)?<br>'\n",
        "      match = re.search(pattern, df_row, re.DOTALL)\n",
        "      if match:\n",
        "        key_phrase_found = True\n",
        "        # Extract the content following the match\n",
        "        text_after_match = df_row[match.start():]\n",
        "        # Select paragraph with keyword\n",
        "        soup4 = BeautifulSoup(text_after_match, 'html.parser')\n",
        "        element = soup4.find('p')\n",
        "\n",
        "        # Append the segment after the match that does not contain any stopphrase to the qualifying section\n",
        "        if not check_stop_phrases_element(element):\n",
        "          qualifications.append(truncate_text_on_stopphrase(element))\n",
        "          break\n",
        "\n",
        "      # Execute if none of the previous conditions or patterns match a keyphrase\n",
        "      if found == False:\n",
        "        # Iterate over elements found in the BeautifulSoup object and check if the element's tag name is in the list of specified tags\n",
        "        for element in soup.find_all():\n",
        "            # Ensure the element has a string value, that the key_phrase is present in the string\n",
        "            # Verify that key_phrase is not in key_phrases_exact_match (unless it is an exact match)\n",
        "            # Confirm that none of the stop_phrases are present in the element's string\n",
        "            if element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i','u','em', 'span', 'font', 'a'] and element.string != None and key_phrase in element.string and len(element.string.split()) < 10 and ((key_phrase not in key_phrases_exact_match or key_phrase == element.string)) and all(stop_phrase not in element.string for stop_phrase in stop_phrases):\n",
        "                found = True\n",
        "                key_phrase_found = True\n",
        "                break\n",
        "            # Check if the element's tag is in the list of specified tags\n",
        "            # Check if the element's stripped text matches the key_phrase or its variations with specific suffixes\n",
        "            if element.name in ['p', 'div', 'ul', 'li'] and (element.text.strip() in [key_phrase, key_phrase + ':', key_phrase + ';', key_phrase + '-']):\n",
        "                found = True\n",
        "                key_phrase_found = True\n",
        "                break\n",
        "\n",
        "      # If keyphrase has been found, extraction of sentences which include qualification\n",
        "      if found:\n",
        "          # Stores qualifications temporarily\n",
        "          temporary_qualifications = []\n",
        "\n",
        "          # Find first element occurring after keyphrase\n",
        "          if element:\n",
        "            next_element = element.find_next()\n",
        "          else:\n",
        "            # Break if next element is None\n",
        "            break\n",
        "\n",
        "          # Track the number of words after key_phrase\n",
        "          word_count = 0\n",
        "\n",
        "          # Continue the loop while tag name is not in ['p', 'ul', 'li', 'ol', 'div']\n",
        "          # And either the word count is less than 60 or the next_element's tag name is 'font' or 'span'\n",
        "          while next_element and next_element.name not in ['p', 'ul', 'li', 'ol','div'] and (word_count < 60 or next_element.name == 'font' or next_element.name == 'span'):\n",
        "\n",
        "              # Skip None type elements\n",
        "              if next_element is None:\n",
        "                  continue\n",
        "\n",
        "              # Find next element\n",
        "              next_element = next_element.find_next()\n",
        "\n",
        "              if next_element:\n",
        "                # Special case to track word count for <br> elements\n",
        "                if next_element.name in ['br'] and next_element.previous_sibling:\n",
        "\n",
        "                  # Stop extracting if one of the stopwords was dedected\n",
        "                  if check_stop_phrases_element_text(next_element.previous_sibling.text.strip()):\n",
        "                    break\n",
        "\n",
        "                  # Increase word_count by the number of words of the previous sibling element\n",
        "                  word_count += len(next_element.previous_sibling.text.split())\n",
        "\n",
        "                else:\n",
        "                  # Increase word_count by the number of words of the element\n",
        "                  word_count += len(next_element.get_text().split())\n",
        "              # Break if word_count >= 60 and no ul element within the next_element\n",
        "              if word_count >= 60 and not next_element.find('ul'):\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "          allow_br = False  # Variable to check if the <br> element should be allowed\n",
        "          allow_em = False  # Variable to check if the <em> element should be allowed\n",
        "\n",
        "\n",
        "          while next_element and (next_element.name in ['p', 'ul', 'li', 'div', 'ol'] or (next_element.name == 'br' and allow_br) or (next_element.name == 'em' and allow_em)):\n",
        "              #Tracks if p or ul section was found\n",
        "              p_ul_found = True\n",
        "\n",
        "              # # Set variables to True to continue the loop if any of the specified elements occur\n",
        "              if next_element.name in ['p', 'ul', 'li', 'div', 'ol']:\n",
        "                  allow_br = True\n",
        "                  allow_em = True\n",
        "\n",
        "              # Stops extracting if one of the stopwords was dedected within the first 50 characters\n",
        "              if any(stop_phrase in ' '.join(next_element.text.split()[:50]) for stop_phrase in stop_phrases):\n",
        "                break\n",
        "\n",
        "              # Stops extracting if one of the stopwords was dedected\n",
        "              if next_element.string != None and any(stop_phrase_exact_match == re.sub(r'[^\\w\\s]', '', next_element.string.strip()) for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "                break\n",
        "\n",
        "              #########\n",
        "              # Lists\n",
        "              #########\n",
        "              if next_element.name in ['ul','li','ol']:\n",
        "                  # Track if ul list was found\n",
        "                  ul_list_found = True\n",
        "\n",
        "                  ###################################\n",
        "                  # Option #1: There is a valid list element\n",
        "                  ###################################\n",
        "                  if next_element.find_all('li', recursive=False) != []:\n",
        "                    for li in next_element.find_all('li', recursive=False):\n",
        "                        # Checking for stopphrase and break if detected\n",
        "                        if check_stop_phrases_element(li):\n",
        "                          break\n",
        "                        # Special case that there is a second list within a list\n",
        "                        # Only valid if less than 3 sentences have been collected so far, otherwise it will be skipped\n",
        "                        if li.find('ul'):\n",
        "                          if len(set(temporary_qualifications)) < 3:\n",
        "                            qualifications.append(li.text)\n",
        "                            temporary_qualifications.append(li.text)\n",
        "                            section_found = True\n",
        "                          else:\n",
        "                            continue\n",
        "                        # Extract qualification sentences\n",
        "                        else:\n",
        "                          qualifications.append(truncate_text_on_stopphrase(li))\n",
        "                          temporary_qualifications.append(truncate_text_on_stopphrase(li))\n",
        "                          section_found = True\n",
        "\n",
        "\n",
        "                        #  Check if the current list section is concluded by checking the next element\n",
        "                        next_element_check = li.find_next()\n",
        "                        if next_element_check and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u', 'p','em', 'a']:\n",
        "                          if any(qualification not in key_phrases for qualification in temporary_qualifications) and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u', 'p','em', 'a']:\n",
        "                              break\n",
        "\n",
        "                  ###################################\n",
        "                  # Option #2: there is no list begining tag\n",
        "                  ###################################\n",
        "                  else:\n",
        "                    if next_element.previous_sibling:\n",
        "                      for li in next_element.previous_sibling.find_all_next('li', recursive=False):\n",
        "                        # Check for stopphrase and break if detected\n",
        "                        if check_stop_phrases_element(li):\n",
        "                          break\n",
        "\n",
        "                        # Detects <strong> elements within a <li> element containing a key_phrase and skips it\n",
        "                        if li.find('strong'):\n",
        "                            strong_element = li.find('strong')\n",
        "                            for key_phrase in key_phrases:\n",
        "                              if strong_element.string and key_phrase in strong_element.string:\n",
        "                                continue\n",
        "                            # Appen it to qualifications if no key_phrase in it\n",
        "                            qualifications.append(li.text)\n",
        "                            temporary_qualifications.append(li.text)\n",
        "                            section_found = True\n",
        "                        if li.find('ul'):\n",
        "                            continue\n",
        "                        else:\n",
        "                            # Append sentences to qualifications\n",
        "                            qualifications.append(truncate_text_on_stopphrase(li))\n",
        "                            temporary_qualifications.append(truncate_text_on_stopphrase(li))\n",
        "                            section_found = True\n",
        "\n",
        "                        # Check if all li elements has been completely extracted\n",
        "                        next_element_check = li.find_next()\n",
        "                        if next_element_check and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u', 'p','em', 'a']:\n",
        "                          if any(qualification not in key_phrases for qualification in temporary_qualifications) and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u', 'p','em', 'a']:\n",
        "                              break\n",
        "\n",
        "                  # Find next sibling element\n",
        "                  next_element_check = next_element.find_next_sibling()\n",
        "\n",
        "                  # Check whether the current list has been completely extracted\n",
        "                  if next_element_check and not (next_element_check.text == '' and next_element_check.name == 'p'):\n",
        "                    if next_element_check and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u','em', 'a']:\n",
        "                      if any(qualification not in key_phrases for qualification in temporary_qualifications) and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u' ,'em', 'a']:\n",
        "                          break\n",
        "\n",
        "              ###########\n",
        "              # Sections\n",
        "              ###########\n",
        "              # Extract <p> elements which have a textual content\n",
        "              if next_element.name == 'p' and next_element.text.strip() != \"\":\n",
        "                if next_element.string == None:\n",
        "                  qualifications.append(truncate_text_on_stopphrase(next_element))\n",
        "                  section_found = True\n",
        "                else:\n",
        "                  qualifications.append(next_element.string)\n",
        "                  section_found = True\n",
        "                next_element_check = next_element.find_next_sibling()\n",
        "\n",
        "                # Check if p sections has been completely extracted\n",
        "                if next_element_check and next_element_check.name not in ['font', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong', 'p', 'b','ol', 'u','em', 'a']:\n",
        "                    break\n",
        "\n",
        "              ###############\n",
        "              # Div elements\n",
        "              ###############\n",
        "              if next_element.name == 'div':\n",
        "                # Check if there is a stop phrase within the element text\n",
        "                if not any(stop_phrase in next_element.text for stop_phrase in stop_phrases):\n",
        "                  qualifications.append(next_element.text)\n",
        "                  section_found = True\n",
        "\n",
        "                # Check if div sections has been completely extracted\n",
        "                next_element_check = next_element.find_next_sibling()\n",
        "                if next_element_check and next_element_check.name not in ['font', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','b','ol', 'div', 'u','em', 'a']:\n",
        "                    break\n",
        "\n",
        "              # Find next element\n",
        "              if next_element.find_next_sibling() is None:\n",
        "                next_element = next_element.find_next()\n",
        "              else:\n",
        "                next_element = next_element.find_next_sibling()\n",
        "\n",
        "\n",
        "          # Case no section or list element was found\n",
        "          if not p_ul_found:\n",
        "              # Case 1: Qualifications within a strong tag\n",
        "              # Find the index of the closing </strong> tag after the keyword\n",
        "              closing_tag_index = df_row.find('</strong>', df_row.find(key_phrase))\n",
        "\n",
        "              # Check if a closing tag index was found\n",
        "              if closing_tag_index != -1:\n",
        "                  # Find the index of the next opening <strong> tag\n",
        "                  opening_tag_index = df_row.find('<strong>', closing_tag_index)\n",
        "                  if opening_tag_index != -1:\n",
        "                      # Extracts the text between the two tags\n",
        "                      text_between_strong = df_row[closing_tag_index + len('<strong>'):opening_tag_index]\n",
        "\n",
        "                      # Stops extracting if one of the stopwords has been dedected\n",
        "                      if check_stop_phrases_element_text(text_between_strong):\n",
        "                        break\n",
        "\n",
        "                      else:\n",
        "                        # Add the text to qualifications\n",
        "                        qualifications.append(text_between_strong.strip())\n",
        "\n",
        "\n",
        "              # Case 2: Qualifications/Key phrase within a <b>-tag\n",
        "              # Find all <b>-tags\n",
        "              b_tags = soup.find_all('b')\n",
        "              text_between_b_tags = ''\n",
        "\n",
        "              # Iterate through all <b> tag\n",
        "              for i in range(len(b_tags)):\n",
        "                text_between_b_tags = ''\n",
        "                if key_phrase in b_tags[i].text:\n",
        "                    next_element = b_tags[i].find_next_sibling()\n",
        "                    word_count = 0\n",
        "                    # Check if the current iteration is the last index of the b_tags list\n",
        "                    if i == len(b_tags) - 1:\n",
        "                      if next_element and next_element.name == 'br' and next_element.previous_sibling:\n",
        "\n",
        "                            # Stops extracting if one of the stopwords has been dedected\n",
        "                            if check_stop_phrases_element_text(next_element.previous_sibling.text.strip()):\n",
        "                              break\n",
        "\n",
        "                            # Reset word count when encountering a <br> tag\n",
        "                            word_count = 0\n",
        "                            words = next_element.previous_sibling.text.split()\n",
        "                            word_count += len(words)\n",
        "\n",
        "                            # Filter out large paragraphs which likely to be description of the company\n",
        "                            if word_count <= 75:\n",
        "                                qualifications.append(next_element.previous_sibling.text.strip())\n",
        "                            if next_element is not None:\n",
        "                              next_element = next_element.find_next()\n",
        "\n",
        "                    # Case, qualifications are separated by <br> elements\n",
        "                    while next_element and (next_element.name == 'br'):\n",
        "\n",
        "                        # Stops extracting if one of the stopwords has been dedected\n",
        "                        if check_stop_phrases_element_text(next_element.previous_sibling.text.strip()):\n",
        "                          break\n",
        "\n",
        "                        if next_element and next_element.name == 'br' and next_element.previous_sibling:\n",
        "\n",
        "                            # Reset word count when encountering a <br> tag\n",
        "                            word_count = 0\n",
        "                            words = next_element.previous_sibling.text.split()\n",
        "                            word_count += len(words)\n",
        "\n",
        "                            # Filter out large paragraphs which likely to be description of the company\n",
        "                            if word_count <= 75:\n",
        "                              qualifications.append(next_element.previous_sibling.text.strip())\n",
        "\n",
        "                              # Handle the case of the last sentence in the qualifications section (a tag other than <br> is encountered)\n",
        "                              if next_element.find_next() and next_element.find_next().name != 'br':\n",
        "                                  pre_next_element = next_element.find_next()\n",
        "\n",
        "                                  # Stops extracting if one of the stopwords was dedected\n",
        "                                  if not any(stop_phrase in pre_next_element.find_previous().text for stop_phrase in stop_phrases):\n",
        "                                    qualifications.append(pre_next_element.find_previous().text.strip())\n",
        "\n",
        "                                  # Stops extracting if one of the stopwords was dedected\n",
        "                                  elif next_element.string != None and not any(stop_phrase_exact_match == re.sub(r'[^\\w\\s]', '', pre_next_element.find_previous().text) for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "                                    qualifications.append(pre_next_element.find_previous().text.strip())\n",
        "\n",
        "                              # Handle the case of the last sentence in the qualifications section (no tag is encountered)\n",
        "                              elif next_element.find_next() == None:\n",
        "                                filtered_html = ''.join(str(element) for element in next_element.next_siblings if element != '\\n')\n",
        "\n",
        "                                # Stops extracting if one of the stopwords was dedected\n",
        "                                if not any(stop_phrase in filtered_html for stop_phrase in stop_phrases):\n",
        "                                  qualifications.append(filtered_html)\n",
        "\n",
        "                            # Find next element\n",
        "                            if next_element is not None:\n",
        "                              next_element = next_element.find_next()\n",
        "\n",
        "              # Case Keyphrase has been found but no list or section was found\n",
        "              if found:\n",
        "                # In some cases there is a br tag within the strong tag, in this case we find the next tag\n",
        "                if element.name == 'strong':\n",
        "                  element = element.find_next()\n",
        "\n",
        "                # Skip the first <br> tag since the first qualification sentence comes after it\n",
        "                if element.name == 'br':\n",
        "                  next_element = element.find_next()\n",
        "\n",
        "                # <strong> element should only be allowed after br or span element\n",
        "                allow_strong = False\n",
        "                # Case #1, qualifications are separated by <br> elements\n",
        "                while next_element and ((next_element.name in ['br', 'span']) or (allow_strong and next_element.name in ['br', 'span', 'strong', 'b'])):\n",
        "                        allow_strong = True\n",
        "\n",
        "                        if next_element and next_element.name in ['br', 'span'] and next_element.previous_sibling:\n",
        "\n",
        "                            # Reset word count\n",
        "                            word_count = 0\n",
        "                            words = next_element.previous_sibling.text.split()\n",
        "                            word_count += len(words)\n",
        "\n",
        "                            # Stops extracting if one of the stopwords was dedected\n",
        "                            if check_stop_phrases_element_text(next_element.previous_sibling.text.strip()):\n",
        "                              break\n",
        "\n",
        "                            # Filter out large paragraphs which likely to be description of the company\n",
        "                            if word_count <= 40:\n",
        "                                qualifications.append(next_element.previous_sibling.text.strip())\n",
        "\n",
        "                                # Handle the case of the last sentence in the qualifications section\n",
        "                                if next_element.next_sibling and next_element.next_sibling.name != 'br':\n",
        "\n",
        "                                  # Stops extracting if one of the stopwords was dedected\n",
        "                                  if not any(stop_phrase in next_element.next_sibling.text for stop_phrase in stop_phrases):\n",
        "                                    qualifications.append(next_element.next_sibling.text.strip())\n",
        "\n",
        "                                  # Stops extracting if one of the stopwords was dedected\n",
        "                                  elif next_element.string != None and not any(stop_phrase_exact_match == re.sub(r'[^\\w\\s]', '', next_element.next_sibling.text.strip()) for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "                                    qualifications.append(next_element.next_sibling.text.strip())\n",
        "\n",
        "                        # Find next element\n",
        "                        if next_element is not None:\n",
        "                          next_element = next_element.find_next()\n",
        "\n",
        "                # Case #2, qualifications are within table rows\n",
        "                if soup.find('tr') is not None and key_phrase in key_phrases_without_exact_match:\n",
        "                  start_index = df_row.find(\"<tr>\", df_row.find(key_phrase))\n",
        "                  end_index = df_row.find(\"</tr>\", start_index) + len(\"</tr>\")\n",
        "\n",
        "                  next_tr = df_row[start_index:end_index]\n",
        "                  soup2 = BeautifulSoup(next_tr, 'html.parser')\n",
        "\n",
        "                  # Extract text from the HTML\n",
        "                  if soup2.get_text() and not check_stop_phrases_element(soup2):\n",
        "                    qualifications.append(soup2.get_text())\n",
        "\n",
        "                  if soup2.get_text().strip():\n",
        "                    tr_found = True\n",
        "                    key_phrase_found = True\n",
        "\n",
        "\n",
        "                # Case #3: Key_phrase is in an string element within a paragraph\n",
        "                pattern = rf'<strong>{re.escape(key_phrase)}:</strong>(.*?)</p>'\n",
        "                match = re.search(pattern, df_row, re.DOTALL)\n",
        "                if match:\n",
        "                    qualifications.append(match.group(1).strip())\n",
        "\n",
        "          # Section has been found\n",
        "          section_found = True\n",
        "\n",
        "    # Case no section and no keyphrase has been found\n",
        "    if section_found == False:\n",
        "        # Case keyphrase within an <ul>-tag/<li>-tag\n",
        "        ul_tags = soup.find_all('ul')\n",
        "        for ul_tag in ul_tags:\n",
        "          if key_phrase in ul_tag.text:\n",
        "              li_tags = ul_tag.find_all('li')\n",
        "              for li_tag in li_tags:\n",
        "                if key_phrase in li_tag.text:\n",
        "                  next_li_tags = li_tag.find_all_next('li')\n",
        "                  for next_li_tag in next_li_tags:\n",
        "                    if key_phrase not in next_li_tag.text:\n",
        "                      qualifications.append(next_li_tag.text.strip())\n",
        "                  break\n",
        "\n",
        "    # Remove remaining html tags\n",
        "    qualifications = [BeautifulSoup(text, \"html.parser\").get_text() for text in qualifications]\n",
        "\n",
        "    # Remove special characters\n",
        "    qualifications = [text.replace(\"<\", \"\").replace(\">\", \"\").replace(\"•\", \"\") for text in qualifications]\n",
        "\n",
        "    # Remove multiple spaces and line breaks\n",
        "    qualifications = [re.sub(r'\\s+', ' ', text) for text in qualifications]\n",
        "\n",
        "    # Remove duplicates #1\n",
        "    qualifications = list(set(qualifications))\n",
        "\n",
        "    # Remove leading/trailing whitespace and filter out empty qualifications\n",
        "    qualifications = [qualification.strip() for qualification in qualifications if qualification.strip()]\n",
        "    qualifications = list(filter(None, qualifications))\n",
        "\n",
        "    # Filter qualifications based on alphabetical characters and key phrases\n",
        "    qualifications = filter_and_clean_qualifications(qualifications)\n",
        "\n",
        "    # Remove list items that only contain stopwords\n",
        "    qualifications = [item for item in qualifications if not any(word == item for word in stop_words)]\n",
        "\n",
        "    # Remove duplicates #2\n",
        "    qualifications = list(set(qualifications))\n",
        "\n",
        "    # Exclude sentences that are already contained in other paragraphs\n",
        "    qualifications = filter_duplicates(qualifications)\n",
        "\n",
        "\n",
        "    if len(qualifications) == 0 and key_phrase_found:\n",
        "      print('Skills can not be detected!')\n",
        "      return('Skills can not be detected!')\n",
        "    elif len(qualifications) == 0 and not key_phrase_found:\n",
        "      print('Keyphrase can not be detected!')\n",
        "      return('Skills can not be detected!')\n",
        "    else:\n",
        "      print(qualifications)\n",
        "      return qualifications"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Extraction of qualification section"
      ],
      "metadata": {
        "id": "mPVgo0Mw7YSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Extraction of qualification for whole dataset"
      ],
      "metadata": {
        "id": "rYLxFb_tyQb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_data['qualifications'] = job_data.apply(lambda row: (print(row['id']), extract_qualification_section(row['rawDescriptionTranslated']))[1], axis=1)"
      ],
      "metadata": {
        "id": "b9Vtgt59DZRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Extraction method for one specific job ad (for development purposes only)"
      ],
      "metadata": {
        "id": "_B3cs21g72lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define text for single extraction\n",
        "j = 0\n",
        "text = \"\"\"<b>description</b><br><br>junior data analyst<br>we are hiring for several shifts: monday to friday morning and monday to friday afternoon.<br><br>are you passionate about leveraging data to deliver actionable insight that impacts daily business decision of amazon in a promising new market segment?<br>does the prospect of dealing with massive volume of data excite you?<br>amazon is seeking a transportation performance analyst to join amazon's european special handling (eu sh) team. eu sh team is responsible for the end-to-end heavy/bulky journey in the fulfilment, supply chain and transportation daily business and its strategic vision in europe.<br>amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable. during our day to day operations, tons of data is generated which is leveraged to take our important business decisions.<br>our ideal candidate thrives in a fast-paced environment, relishes working with large transactional volumes and big data, enjoys the challenge of highly complex business contexts (that are typically being defined in real-time), and, above all else, is passionate about data and analytics.<br>as an analyst you will be developing sql/etl queries, accessing data warehouse and redshift clusters, creating automated reports through macros, creating relevant kpis and metrics for performance of team as well as for transportation operations. publish daily/weekly performance reports. you will give us business insights based upon data to further improve our operations and processes.<br><br>a successful candidate knows and loves working with business intelligence tools, is comfortable accessing and working with big data from multiple sources, and passionately partners with the business to identify strategic opportunities and deliver results.<br><br>you should have an internal drive to answer \"why?\" questions, excellent analytical abilities and strong technical skills.<br><br>responsibilities:<br><br>- create metrics, performance dashboards and reports<br>- drive root cause analysis<br>- engage with cross-functional teams and/or carriers/vendors for implementation of project/program requirements<br>- managing multiple projects/initiatives<br>- communication at all levels with the ability to present information professionally &amp; concisely with supporting data<br><br><b>basic qualifications</b><br><br>- vba, sql or other coding experience to support automation initiatives<br>- working experience with data visualization tools such as tableau, power bi or quicksight.<br><br><b>preferred qualifications</b><br><br>- experience in business process improvement, lean/six sigma<br>- proven independent decision making skills in an often times ambiguous environment.<br>- ability to think quantitatively and qualitatively about operating processes and outcomes<br>- previous experience within transportation or logistics.<br><br>amazon is an equal opportunities employer. we believe passionately that employing a diverse workforce is central to our success.<br>we make recruiting decisions based on your experience and skills. we value your passion to discover, invent, simplify and build. protecting your privacy and the security of your data is a longstanding top priority for amazon. please consult our privacy notice to know more about how we collect, use and transfer the personal data of our candidates\"\"\""
      ],
      "metadata": {
        "id": "vEQth70LE8Hk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract single skill section\n",
        "'''\n",
        "j = 0\n",
        "if extract_qualification_section(text) is not None:\n",
        "  for i in extract_qualification_needed(text):\n",
        "    j = j + 1\n",
        "    print(j)\n",
        "    print(i)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9aKmX98nzuVW",
        "outputId": "bfda5e5f-49c3-474f-e4e3-a37cfa1b9d5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nj = 0\\nif extract_qualification_section(text) is not None:\\n  for i in extract_qualification_needed(text):\\n    j = j + 1\\n    print(j)\\n    print(i)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Export extracted Qualifications"
      ],
      "metadata": {
        "id": "30eSmp_88XGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Preparing data for export"
      ],
      "metadata": {
        "id": "CkYyDAN7zHsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list to string\n",
        "job_data['qualifications'] = job_data['qualifications'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)"
      ],
      "metadata": {
        "id": "wYwQuwb1xrsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for job ads where qualifications were detected\n",
        "job_data = job_data[job_data['qualifications'] != 'Skills can not be detected!']"
      ],
      "metadata": {
        "id": "-Sa5kG7c0_7o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export detected skills\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define stopwords\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "# Removing stopwords\n",
        "job_data['description'] = job_data['qualifications'].apply(lambda x: \" \".join(x for x in x.split() if x not in stopwords))\n",
        "\n",
        "# Tokenize job description\n",
        "job_data[\"descriptionTokenized\"] = job_data[\"description\"].apply(nltk.word_tokenize)\n",
        "\n",
        "# Export dataframe to excel\n",
        "job_data.to_excel('job_data_preprocessed_extracted_qualifications.xlsx', index=False)"
      ],
      "metadata": {
        "id": "9KVSo0Y8zDXg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}