{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1M1g50UX9WZ+0AH7oeg6O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schmcklr/skill_extractor/blob/main/skill_extractor_section_extract_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2:** Skill Section Extraction\n",
        "\n",
        "This specialized program systematically extracts the qualification section from english job ads by scouring the HTML source code. It identifies key phrases and specific patterns, derived from the analysis of over 1500 job ads. The extracted qualifications, along with the remaining job ad data, are compiled in a data frame and exported to an Excel file for further analysis. Ads where the qualification section couldn't be extracted are automatically excluded from the export.\n"
      ],
      "metadata": {
        "id": "1jpJ4wf6tSh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load preprocessed data\n",
        "*   Import of translated job advertisements ([part 1](https://colab.research.google.com/drive/1BgayjC-opiqcTT_QLv6RGG9a5roDLK9D#scrollTo=1qwXDcfoCAvZ))\n"
      ],
      "metadata": {
        "id": "soa-t2_96UwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Fetching raw data\n",
        "workbook = 'https://github.com/schmcklr/skill_extractor/blob/main/job_data/job_data_general_preprocessed_and_translated.xlsx?raw=true'\n",
        "\n",
        "# Import of tabs\n",
        "job_data = pd.read_excel(workbook, sheet_name=\"Sheet1\")"
      ],
      "metadata": {
        "id": "2M-ZwW1AfHtg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Function Definitions"
      ],
      "metadata": {
        "id": "K2XUY2Qk6n7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   filter_duplicates\n",
        "*   filter_key_phrases\n",
        "*   check_stop_phrases_element\n",
        "*   check_stop_phrases_element_text\n",
        "*   truncate_text_on_stopphrase\n",
        "*   filter_and_clean_qualifications\n",
        "*   extract_qualification_section"
      ],
      "metadata": {
        "id": "3pgsBbvp7vOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Filter duplicates"
      ],
      "metadata": {
        "id": "b03oosFs66dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter duplicated sentences\n",
        "def filter_duplicates(sentences):\n",
        "    filtered_sentences = []\n",
        "    sentences = sorted(sentences, key=len, reverse=True)\n",
        "    for sentence in sentences:\n",
        "        if all(sentence not in other_sentence for other_sentence in filtered_sentences):\n",
        "            filtered_sentences.append(sentence)\n",
        "    return filtered_sentences"
      ],
      "metadata": {
        "id": "wjjenLLNfF9C"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Filter key phrases"
      ],
      "metadata": {
        "id": "-rfE_TrK69oQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter key phrases by removing key_phrases which are in list key_phrases_exact_match\n",
        "def filter_key_phrases(key_phrases, key_phrases_exact_match):\n",
        "    filtered_phrases = []\n",
        "    for phrase in key_phrases:\n",
        "        if not any(phrase == match for match in key_phrases_exact_match):\n",
        "            filtered_phrases.append(phrase)\n",
        "    return filtered_phrases"
      ],
      "metadata": {
        "id": "oWW0Afu-7CMk"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Stopphrase checking"
      ],
      "metadata": {
        "id": "VDEhGQHckCQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Element\n",
        "# Stop extracting if one of the stopphrases has been dedected\n",
        "def check_stop_phrases_element(next_element):\n",
        "  # Clean the text by removing non-alphanumeric characters and whitespace characters\n",
        "  if next_element and next_element.string != None:\n",
        "    cleaned_element_text = re.sub(r'[^\\w\\s]', '', next_element.string.strip())\n",
        "\n",
        "  # Detect stop_phrases within the first 45 characters\n",
        "  if any(stop_phrase in ' '.join(next_element.text.split()[:45]) for stop_phrase in stop_phrases):\n",
        "    # Only used for developing context\n",
        "    #matched_phrases = [stop_phrase for stop_phrase in stop_phrases if stop_phrase in ' '.join(next_element.text.split()[:50])]\n",
        "    #if matched_phrases:\n",
        "      #print('Stopphrase detected:', matched_phrases[0])\n",
        "\n",
        "    return True\n",
        "  # Detect stop_phrases_exact_match\n",
        "  if next_element and next_element.string != None and any(stop_phrase_exact_match == cleaned_element_text for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "    return True\n",
        "\n",
        "  return False"
      ],
      "metadata": {
        "id": "feEIUHeTkCAP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Element text\n",
        "# Stop extracting if one of the stopphrases has been dedected\n",
        "def check_stop_phrases_element_text(element_text):\n",
        "    cleaned_element_text = re.sub(r'[^\\w\\s]', '', element_text)\n",
        "\n",
        "    if any(stop_phrase in element_text for stop_phrase in stop_phrases):\n",
        "        return True\n",
        "\n",
        "    if cleaned_element_text is not None and any(stop_phrase_exact_match == cleaned_element_text for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "        return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "NzZMtaI56740"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4 Extract section until stopphrase occurs"
      ],
      "metadata": {
        "id": "9ULQTUkKtG-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_text_on_stopphrase(element):\n",
        "    text = element.text\n",
        "\n",
        "    min_index = len(text) # Index of the shortest stop phrase in the text\n",
        "    selected_stop_phrase = None # Selected stop phrase for truncation\n",
        "\n",
        "    for stop_phrase in stop_phrases:\n",
        "        index = text.find(stop_phrase)\n",
        "        if index != -1 and index < min_index:\n",
        "            min_index = index\n",
        "            selected_stop_phrase = stop_phrase\n",
        "\n",
        "    if selected_stop_phrase:\n",
        "        truncated_text = text[:min_index].strip()\n",
        "        return truncated_text\n",
        "    else:\n",
        "        return text"
      ],
      "metadata": {
        "id": "vYHDJ92TtE1d"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5 Filter and clean qualification list"
      ],
      "metadata": {
        "id": "J1UU5BUG1AK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_and_clean_qualifications(qualifications):\n",
        "    filtered_qualifications = []\n",
        "    for qualification in qualifications:\n",
        "        clean_qualification = \"\".join(char for char in qualification if char.isalpha() or char.isspace())\n",
        "        if clean_qualification and clean_qualification not in key_phrases:\n",
        "            filtered_qualifications.append(qualification)\n",
        "    return filtered_qualifications"
      ],
      "metadata": {
        "id": "fUEnHzB11Ld6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6 Definition of lists\n",
        "\n",
        "\n",
        "*   **key_phrases** (for identifying the Skills section)\n",
        "\n",
        "*   **key_phrases_exact_match** (key phrases that should only be recognized when they are within a separate tag element)\n",
        "*   **key_phrases_without_exact_match** (only key phrases which are not in the key_phrases_exact_match)\n",
        "*   **stop_phrases** (phrases that, upon occurrence, should halt the extraction process)\n",
        "*   **stop_phrases_exact_match** (stop phrases that should only be recognized when they are within a separate tag element)\n",
        "*   **stop_words** (words that should be removed from the text)\n",
        "\n"
      ],
      "metadata": {
        "id": "6bgnNl1g0mwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Key Phrases\n",
        "key_phrases = [\n",
        "    'required experience & competencies', 'who we are looking for', 'requirements', 'competencies', 'required skills', 'technical skills', 'education', 'skills required', 'common core skills', 'qualifikationen', 'profile', 'have knowledge in',\n",
        "    'minimum knowledge and skills required', 'was sie mitbringen', 'language skills', 'desired/plus', 'language','desirable attributes', 'skills and experience', 'what we expect from you',\n",
        "    'required/must have', 'core competencies', 'qualifications required', 'essential qualifications', 'position criteria', 'complément du descriptif', 'compétences requises',\n",
        "    'profile description', \"you're at the right place, if\", 'skills and competencies', 'competencies required', 'professional qualification', 'soft skills',\n",
        "    'we are looking for people, who are', 'qualifications', 'your background', 'must have', 'nice to have', 'your profile', 'compétences', 'votre profil', 'your skills', 'you...', 'you:',\n",
        "    'languages', 'personal abilities', 'required competencies', 'compétences requises', 'profil candidat', \"le plus de l'offre\", '候选人能力&amp;要求', 'experience and education',\n",
        "    'your qualities', 'what will make you successful', \"who we're looking for\", 'basisqualifikationen', \"what you'll bring to us\", \"dein profil\", 'what we are looking for',\n",
        "    'skills', 'knowledge', 'your strengths', 'required technical', 'professional expertise', 'preferred technical and professional expertise', 'you bring that with', 'what you need is',\n",
        "    'an ideal candidate will be', 'minimum qualifications', 'preferred qualifications', 'basic qualifications', 'your qualifications', 'about you', 'profil', 'your personality','your qualification', 'what you need to have',\n",
        "    'who are you?', 'ihr profil', 'do i qualify?', 'requisitos', 'they fit us.', \"what you’ll need\", 'come as you are', 'your story', 'are you a fit?', 'we’re looking for people who', 'what are we looking for',\n",
        "    '· you are in your last semester of a bachelor’s or master’s program or have graduated less than six months ago', 'job requirements', 'required skills:', 'preferred skills:',\n",
        "    'do you have what it takes to be the field sales manager', 'you', 'who are we looking for', 'the perfect candidate', 'qualification','experience & key skills', 'studied:', 'skills to create thrills',\n",
        "    'das bringen sie mit', 'candidate:', 'skills & qualifications', 'for people with many qualities', 'who you are', 'required profile', 'we are looking for people who', 'about the candidate',\n",
        "    'we are seeking highly motivated individuals who meet the following criteria', 'qualifications and skills', 'you are…', \"if you’re a good fit, you’ll have\", \"if you’re a really good fit, you’ll have\",\n",
        "    'am i a perfect match', 'to qualify for the role you must have', 'education and qualifications / skills and competencies', 'is it you, we are looking for', 'main competence requirement',\n",
        "    'expérience requise et formation', 'expérience requise et formation', 'experience', 'personal competencies', 'digital competencies', 'managerial competencies',\n",
        "    'required education', 'we are looking for someone who has', 'will be an advantage if the candidate has', 'you score with us', \"what you'll bring to us\", 'expérience requise et formation',\n",
        "    'you are best equipped for this task if you have','# profile # competences', 'we look for', 'connaissances/expérience', 'do you have what it takes', 'profil recherché', 'personal skills', 'you are...','technical knowledge',\n",
        "    'to fit in the role, you also have', 'requirement', 'what we expect', 'your profile  ready to step on the gas', \"what we’re looking for\", 'formula for success', 'seeked profile',\n",
        "    'what will you bring to hp?', 'this is you', 'required skills', 'preferred skills', ' you are an accounting professional', 'experience and specific knowledge', \"are you the process innovator we're looking for?\",\n",
        "    'your profile  B', 'you bring that with –f ä', 'so you score with us', \"what you'll need\", 'wanted profile', 'your background looks like', 'bringing ', 'what we are expecting',\n",
        "    'this scores with us', 'in this you are a specialist', 'you can see you in this function when you', 'what you need', 'job skills and knowledge required', \"here's what we require\",\n",
        "    \"to be successful in this role you will need the following\", 'who you are?', \"you'll be the right fit if you\", \"you`ll be the right fit if you have\", 'what will you bring',\n",
        "    \"you’ll need to have\", \"we’d love to see\", \"In this you are a specialist\", \"this is what you`ll bring to us\", \"we're looking for people who\", \"am i qualified\", \"you'll need to have\",\n",
        "    \"you specialist\", \"expected skills\", \"you bring\", \"you ...\", \"the ideal candidate will meet the following requirements\", \"what we're looking for\", 'professional skills', 'specific competencies',\n",
        "    \"anforderungsprofil\", \"your skills  talents\", \"therefore fit us\", \"what else will make you successful\", \"the following requirement profile bring with\", \"this is the case with\", 'stating the job reference',\n",
        "    'essential experience', \"desirable experience\", \"we'd love to see\", \"requisitos\", 'you are a perfect fit for us if you', 'anforderungen/ kenntnisse', 'requirements', 'key skills, capabilities',\n",
        "    'what can you contribute', \"a motivated enthusiastic personality with a good understanding of the relationships between the business and the it your way of working can be described as independent responsible and solutionoriented furthermore you have the following background\",\n",
        "    'successful applicants will likely possess most of these', 'what do you bring with', 'required technical and professional expertise', 'what will make you successful', 'qualifikationen', 'desired',\n",
        "    'personality', 'knowledge & experience', 'this is what your background looks like', 'you have', 'technical and professional skills', 'behavioural competency required', 'competency', 'behaviour',\n",
        "    ' personal competencies', 'you also have the following qualities', 'essential skills', 'personal attributes', 'preferred qualifications', 'additional important requirements', 'role competencies',\n",
        "    'minimum education requirements', 'personal competencies', 'key skills', 'you are best equipped for this work, if you', 'target disciplines and special skills', 'to fit in the role, you also',\n",
        "    'further skills', 'it skills', 'language skills', 'studies', 'studied', 'minimum education and experience', 'candidate profile', 'ideal candidate', 'technical requirements', 'further requirements',\n",
        "    'desired requirements', 'technical  professional knowledge', 'working experience', 'preferred tech and prof experience', 'what were looking for', 'to be eligible', 'you need',\n",
        "    'you are interested in or have knowledge in', 'knowledge/technical skills', 'what skills/experience we are looking for', 'how can you make a difference', 'desired  skills & exp erience',\n",
        "    'experience & skills', 'skills &amp; exp', 'desired skills', 'skills / experience', 'preferred requirements', 'required experience','your heroic skills', 'requirements profile',\n",
        "    'requisite skills & experience', 'technical competencies', 'behavioural competencies', 'you are interested in or have knowledge in :', 'knowledge  knowledge  experiences', 'you preferably have',\n",
        "    'required professional and technical expertise', \"to summarise, we're looking for someone with\", 'what we look for', 'besides a technical strong basis we are looking for people who',\n",
        "    'monitoring the administrative organization and the internal controls', 'you have a toyota dna, this means you', 'entry requirements', 'you should apply if you are', 'desired skills & experience',\n",
        "    'education and work experience', \"you are an m/f/x that has proven business judgement and you have a passion for what technology and data science can do. you love working with customers, you aspire to be a domain expert one day in either an entire industry or a process and you get excited when you are influencing change to executives through market-leading saas technology.\",\n",
        "    'required backround and experience', 'educational qualification', 'work experience & qualifications', 'key requirements/experience', 'what you need to succeed', 'qualifikationen und erfahrung', 'valuable skills',\n",
        "    'preferred work experience', 'we expect you to', 'attitude is important! we are looking for people, who are', 'with potential value', 'your skills', 'required', 'desired', 'base compentencies',\n",
        "    'you are looking for an opportunity to accelerate your career in financial management at international level and emerge as a financial leader within a dynamic and challenging organization',\n",
        "    'plus, you fulfill the following hard fact based criteria', 'and you fully agree to these statements', '候选人能力&要求', 'requirements:', 'education', ', schedules, and manage customer expectations',\n",
        "    'experience/knowledge required', 'essential', 'desirable', 'required languages', 'personal required skills', 'skills and knowledge', 'relevant work experience', '2.    knowledge/experience',\n",
        "    'education, experience and skills', 'key success criteria', 'do you have what it takes to be the field sales manager?', 'you are best equipped for this task if you', ' your profile',\n",
        "    '- you have a degree in computer science, business informatics or a comparable education', '- you are passionate about the daimlers concept of innovative payment solutions',\n",
        "    'technical & professional knowledge', 'you are skilled', 'who can apply for the acaddemict business & functional analyst program?', 'skills and qualifications', 'desired experience',\n",
        "    'student profile', 'requirements / knowledge / experience', 'expected profile', 'in order to apply for the graduate programme, you must have', 'profil :', 'you will convince us with',\n",
        "    '##master in engineering, or business administration and at least 3 years of experiences in digital (insurance or web/e-commerce) as a business analyst',\n",
        "    'you have successfully completed your studies in computer science, business informatics, business administration, economics or industrial engineering.handy tools',\n",
        "    \"technical business/data analyst for change initiatives for allianzgi's alternatives investment platform\", 'your skills &amp; talents...', 'hard skills',\n",
        "    'university degree (law / business preferred)', '##support development and continuous improvement of required processes', 'what is your educational background',\n",
        "    'requirements / knowledge / experience< /b', 'education and experience', 'applying creative methods to consume data from is/it sources or move data between is/it solutions in the ecosystem.',\n",
        "    'knowledge / knowledge / experiences', 'preferred skills (good to have)', 'languages required', 'this role requires', 'education and professional background',\n",
        "    'experience in sap functional area as', 'capabilities in new technologies', 'your strengths', 'level of diploma', 'in this they are strong', 'what you deliver',\n",
        "    'we offer the opportunity to develop a fascinating career in exchange for a few requirements', 'high it affinity', 'it knowledge', 'studies/training','your profilebr>',\n",
        "    'in addition, a rotation of at least 3 months in one of our innovation team can be part of one in which it can be done in agile work methodology, big data, machine learningand acquire design thinking, expand your digital skills and expand your own network.',\n",
        "    \"- you develop operations support policies, standards and procedures to improve operational efficiency\", 'in this you are strong', 'in this they are strong',\n",
        "    \"what you should bring\", 'studium', 'you will work with our it development partners in a dynamic environment in modern forms of collaboration, such as. agile development.',\n",
        "    'interface between clients, project members and end users', 'seem profile', 'presentation and discussion ofwork results at management level',\n",
        "    'acceptance test of the implemented requirements as well as expansion of the regression tests', 'prerequisites', 'you bring with -skills with which you shape the future',\n",
        "    'creation ofbusiness analyzes including the specification of the requirements in the context of implementation concepts and user stories as the basis for it programming.',\n",
        "    'if you also pursue your goals with great commitment and characterize you an open personality, you should check in to start together.', 'why are we looking for you',\n",
        "    'we look forward to', 'the best conditions for your entry', 'you are strong', 'minimum knowledge, skills and abilities required', 'knowledge, skills, and abilities',\n",
        "    'effectively manage', 'profile required', 'competence & experience', '…and you also:', 'attitudes', 'it applications', 'behavioural skills'\n",
        "    ]\n",
        "\n",
        "# Key Phrases exact match\n",
        "key_phrases_exact_match = ['you...', 'you:', 'your strengths', 'about you', 'you', 'profil', 'who are', 'ihr profil', 'do i qualify?', 'requisitos', 'they fit us.','your story','skills',\n",
        "                           'are you a fit?', 'candidate:', 'who you are','you are…', 'you are...', 'your skills', 'requirement', 'experience', 'this is you', 'bringing ', 'you specialist',\n",
        "                           \"you ...\", \"we look for\", 'you have', 'education', 'behaviour', 'profile', 'desired','studies', 'it skills', 'erience', 'required', 'essential', 'desirable',\n",
        "                           'knowledge', 'and:', 'essential']\n",
        "\n",
        "# Key Phrases without exact match\n",
        "key_phrases_without_exact_match = filter_key_phrases(key_phrases, key_phrases_exact_match)\n",
        "\n",
        "# Stop phrases\n",
        "stop_phrases = ['audit planning', 'pwc', 'impact/scope', 'offers that convince me', 'what do we offer you', 'additional information', 'we...', 'ubisoft',\n",
        "                'you can look forward to', 'airbus', 'what you’ll get in return', 'send us your application', 'zusätzliche informationen', 'allianz is', 'why amazon',\n",
        "                'airbus', 'candidates who are considered for a position', 'co-ordinating it cover', 'apply today', 'thanks for taking the time', 'application procedure', 'cover letter',\n",
        "                'in order to apply', 'please note that', 'mars', 'all applications will be reviewed', 'please send your application to', 'volvo group', 'contract:',\n",
        "                'stipend and benefits', 'documents to your application', 'your cv in english', 'application and assessment process', 'full-time job', 'reference code','ibm is committed',\n",
        "                'your tasks will be', 'are you interested?', 'tasks in detail', 'studies/training', 'start contract date', 'we offer', 'about us ', 'unibail', 'qualified applicants will receive consideration',\n",
        "                'provide proper reporting', 'can apply', 'huntsville', 'work with external resource', 'you are not a regular helpdesk', 'perks at work', 'about zalando', \"zalando is europe’s leading\", 'internal tech academy',\n",
        "                'further information for your application', 'bmw group', 'experience what moves us', 'contact our recruiting team', 'security/export control statement', 'our offer',\n",
        "                'working conditions', 'if you share our values and vision', 'more opportunities for your development', 'student programs team', 'please no phone calls', 'hat we offer',\n",
        "                'additional information', 'order to be eligible for an internship', 'key dates:', 'what will you work on', 'why netsuite', 'novutech in a nutshell', \"#1 cloud-based\",\n",
        "                \"what's in it for you\", 'place of employment', 'you are going to bring', 'together we will rethink', 'are you ready for a new challenge', 'general function',\n",
        "                'management system provides', 'deloitte-recruiting team', 'what are the central tasks', 'new york it', 'new yorkers offers', \"you'll be working within an audit team\",\n",
        "                'interested?', 'best business school in the world', 'siehe job description', 'graduates working in project controls', \"pour l'analyse de données\", 'in order to structure our',\n",
        "                'recruiting or consulting agency', 'key figures', 'production sites', 'deine benefits', 'you will prepare market', 'transfer pricing structures', 'your benefit',\n",
        "                'application configuration and support','please note', 'we advise corporates', 'seller support center', 'configure and support', 'diversity and inclusion', 'the nestlé group',\n",
        "                \"please don't hesitate and apply\", 'lufthansaglobal business services gmbh', 'messier-dowty', ' canadian controlled', 'equal opportunity employer',\n",
        "                'tasks and responsibilities', 'coach and mentor', 'scor global life americas', 'we are looking forward to your application', 'you make the impossible possible',\n",
        "                'takes responsibility for achieving', 'responsibility for achieving', 'accountabilitytakes', 'permanent job', 'contract :', 'the internship stipend',\n",
        "                'a temporary position', 'stipend and benefits', 'upload your cv', 'you are offered', 'please apply', 'approve monthly/weekly delivery',\n",
        "                'via lufthansa global business services', 'at criteo', 'nestlé is the largest food', 'your responsibilities', 'use analytics', 'appointment date', ' please send',\n",
        "                'application period', 'protecting your privacy', 'singapore r&d office', 'belonging to toyota', 'start -up date', 'at allianz', 'position based in', 'category :',\n",
        "                'with us you are part', 'you have the chance', 'coffee and water', 'our company pension', 'nike european headquarters', 'compelling marketing copy', 'flexible working times',\n",
        "                'tech-unicorns in the world','important note','why us?', 'flat hierarchies', 'scholarship', 'terms & conditions', 'position summary','our tech department', 'benefits', 'grow together',\n",
        "                'free sports', 'about the application process', 'dynamic and international working', 'deliver accurate and timely', 'your next career step', 'analyze, document',\n",
        "                'remember to attach', 'actively shape', 'the department', 'do we want to achieve', 'new yorkers', 'part of our team', 'responsibility and decision-making authority',\n",
        "                'a combination of personal', 'swts manufactures', 'exellys','report to', 'duration: 6 months full-time', 'what’s in it for you', 'accelerate your technical capabilities',\n",
        "                'contact info', 'duration:', 'mobile al', 'note to students', 'allianz group', 'vmware is committed', 'vmware company overview', 'ntry level', 'ibm services is a team',\n",
        "                'about business unit', 'about ses', 'join seb global services', 'to be a part of international company', 'amazon is an equal opportunities', 'join us and', 'timing :',\n",
        "                'diverse, exciting and varied activities', 'nivel de educación', 'presso primarie', 'of responsibility and', 'your win', 'above all of this', 'your day to day', 'contrat',\n",
        "                'equal employment', 'founded in', 'tasks & responsibilities', 'lufthansa consulting delivers'\n",
        "                ]\n",
        "\n",
        "# Stop phrases exact match\n",
        "stop_phrases_exact_match = ['we',  'we offer', 'training and resources', 'location', 'entry level', 'ibm',  'ey', 'deloitte','contract','lufthansa', 'responsibilities',\n",
        "                            'application support', 'basf', 'how to apply', 'salary', 'the application of']\n",
        "\n",
        "# Stop words\n",
        "stop_words = ['key competencies', 'knowledge, skills, qualifications & experience:', 'required:', 'desired:', 'required', 'desired', 'required skills:', 'desired characteristics/skills', 'functional skills:', 'you are:', 'is it you, we are looking for?',\n",
        "              'https://www.bankaustria.at/karriere.jsp', 'knowledge/technical skills', 'what skills/experience we are looking for:', 'licenses/certifications/other',\n",
        "              'entry level', \"ideally, you’ll also have\", 'as per job description.', \"what you'll need\", 'we are willing to cover 2 positions:', 'work experience & qualifications:',\n",
        "              'to qualify for the position(s), you possess the following qualities:', 'who are you?', 'professional qualification routes', 'new graduate',\n",
        "              'educational qualifications:', 'what kind of candidate are we looking for?', 'we are looking for someone that shares the same values as our team:', 'local job requirements',\n",
        "              \"https://www.be-lufthansa.com/de/faqs-be-frifthansa/lufthansa/internship degree work/\", 'you are offered', 'via lufthansa global', 'department description:',\n",
        "              '##support development and continuous improvement of required processes', 'category :', '!our', 'experience :', 'general requirements:', 'preferred skills:',\n",
        "              'profile preferred qualifications', 'profile key requirements', 'ability to:']"
      ],
      "metadata": {
        "id": "Mz4w2xVv0lNl"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6 Main function for skill section extraction"
      ],
      "metadata": {
        "id": "2cWuC1Im7GVN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "nrFa94InE3gz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Identifying key phrases and extracting the qualification section\n",
        "def extract_qualification_section(df_row):\n",
        "    # Tracks if p or ul element has been found\n",
        "    p_ul_found = False\n",
        "    # Tracks if key_phrase has been found\n",
        "    key_phrase_found = False\n",
        "    # Tracks if a key_phrase has been found\n",
        "    found = False\n",
        "    # Tracks if a section has been found\n",
        "    section_found = False\n",
        "    # Tracks if a 'tr' HTML object has been found\n",
        "    tr_found = False\n",
        "\n",
        "    # Initialize list to store qualifications\n",
        "    qualifications = []\n",
        "\n",
        "    # Checking if df_row is of type string\n",
        "    if type(df_row) != str:\n",
        "      print('Row is not of type string')\n",
        "      return('Skills can not be detected!')\n",
        "    else:\n",
        "       df_row = df_row.lower()\n",
        "\n",
        "    # Replace incorrect html tags\n",
        "    df_row = df_row.replace('brong', 'strong')\n",
        "    df_row = df_row.replace('<d>', '<div>')\n",
        "\n",
        "    # Creates a BeautifulSoup object by passing 'df_row' and specifying the parser as 'html.parser'\n",
        "    soup = BeautifulSoup(df_row, 'html.parser')\n",
        "\n",
        "    # Iterate through the list of key_phrases\n",
        "    for key_phrase in key_phrases:\n",
        "\n",
        "      # Reset boolean variables\n",
        "      found = False\n",
        "      p_ul_found = False\n",
        "\n",
        "      # Searches for all specified elements and verifies if a keyphrase is present between the specified element and the following element\n",
        "      # Case that key_phrase is between a div tag and another tag\n",
        "      div_tags = soup.find_all('div')\n",
        "      for i in range(len(div_tags)):\n",
        "        div_element = div_tags[i].find_next()\n",
        "        if div_element and div_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', div_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = div_tags[i]\n",
        "            break\n",
        "          if div_element is not None:\n",
        "            div_element = div_element.find_next()\n",
        "\n",
        "      # Case that key_phrase is between a b tag and another tag\n",
        "      b_tags = soup.find_all('b')\n",
        "      for i in range(len(b_tags)):\n",
        "        b_element = b_tags[i].find_next()\n",
        "        if b_element and b_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', b_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = b_tags[i]\n",
        "            break\n",
        "          if b_element is not None:\n",
        "            b_element = b_element.find_next()\n",
        "\n",
        "      # Case that key_phrase is between a br tag and another tag\n",
        "      # Searches for all defined elements and checks if keyphrase is in the text is between the defined element and the following element\n",
        "      br_tags = soup.find_all('br')\n",
        "      for i in range(len(br_tags)):\n",
        "        br_element = br_tags[i].find_next()\n",
        "        if br_element and br_element.previous_sibling:\n",
        "          previous_sibling_text = br_element.previous_sibling.text\n",
        "          if isinstance(previous_sibling_text, str):\n",
        "              previous_sibling_text = re.sub(r'[^\\w\\s]', '', previous_sibling_text).strip()\n",
        "              # Removing non-alphanumeric characters and whitespace\n",
        "              # Case 1:\n",
        "              if (re.sub(r'[^\\w\\s]', '', key_phrase).strip() in previous_sibling_text and key_phrase in key_phrases_without_exact_match and len(previous_sibling_text.split()) < 6) or (re.sub(r'[^\\w\\s]', '', key_phrase).strip() == previous_sibling_text):\n",
        "                  found = True\n",
        "                  key_phrase_found = True\n",
        "                  element = br_tags[i]\n",
        "                  break\n",
        "              # Case 2:\n",
        "              elif re.sub(r'[^\\w\\s]', '', key_phrase).strip() == previous_sibling_text:\n",
        "                  found = True\n",
        "                  key_phrase_found = True\n",
        "                  element = br_tags[i]\n",
        "                  break\n",
        "          if br_element is not None:\n",
        "            br_element = br_element.find_next()\n",
        "\n",
        "      # Case that key_phrase is between a strong tag and another tag\n",
        "      strong_tags = soup.find_all('strong')\n",
        "      for i in range(len(strong_tags)):\n",
        "        strong_element = strong_tags[i].find_next()\n",
        "        if strong_element and strong_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', strong_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = strong_tags[i]\n",
        "            break\n",
        "          if strong_element is not None:\n",
        "            strong_element = strong_element.find_next()\n",
        "\n",
        "      # Case that key_phrase is between a span tag and another tag\n",
        "      span_tags = soup.find_all('span')\n",
        "      for i in range(len(span_tags)):\n",
        "        span_element = span_tags[i].find_next()\n",
        "        if span_element and span_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', span_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = span_tags[i]\n",
        "            break\n",
        "          if span_element is not None:\n",
        "            span_element = span_element.find_next()\n",
        "\n",
        "\n",
        "      # Case that key_phrase is between a li tag and another tag\n",
        "      li_tags = soup.find_all('li')\n",
        "      for i in range(len(li_tags)):\n",
        "        li_element = li_tags[i].find_next()\n",
        "        if li_element and li_element.previous_sibling:\n",
        "          if re.sub(r'[^\\w\\s]', '', key_phrase).strip() == re.sub(r'[^\\w\\s]', '', li_element.previous_sibling.text).strip():\n",
        "            found = True\n",
        "            key_phrase_found = True\n",
        "            element = li_tags[i]\n",
        "            break\n",
        "          if li_element is not None:\n",
        "            li_element = li_element.find_next()\n",
        "\n",
        "\n",
        "\n",
        "      # Case that key_phrase is between a end tag and another tag\n",
        "      tags = soup.find_all()\n",
        "      for i in range(len(tags) - 1):\n",
        "          # Check if the current tag is an end tag and the next tag is a start tag\n",
        "          if tags[i] and tags[i + 1]:\n",
        "              if tags[i].name and tags[i + 1].name and tags[i].name != tags[i + 1].name:\n",
        "                  next_sibling = tags[i].next_sibling\n",
        "                  if next_sibling and hasattr(next_sibling, 'text'):\n",
        "                      next_sibling_text = next_sibling.text.strip()\n",
        "                      if next_sibling_text:\n",
        "                          stripped_text = (re.sub(r'[^\\w\\s]', '', next_sibling_text))\n",
        "                          if re.sub(r'[^\\w\\s]', '', key_phrase) == stripped_text:\n",
        "                              found = True\n",
        "                              key_phrase_found = True\n",
        "                              element = next_sibling\n",
        "                              break\n",
        "\n",
        "      # Looks for occurrences where the keyphrase appears between a <p> element and a subsequent <br> element\n",
        "      pattern = rf'<p>\\s*{re.escape(key_phrase)}\\s*(:\\s*)?<br>'\n",
        "      match = re.search(pattern, df_row, re.DOTALL)\n",
        "      if match:\n",
        "        key_phrase_found = True\n",
        "        # Extract the content following the match\n",
        "        text_after_match = df_row[match.start():]\n",
        "        # Select paragraph with keyword\n",
        "        soup4 = BeautifulSoup(text_after_match, 'html.parser')\n",
        "        element = soup4.find('p')\n",
        "\n",
        "        # Append the segment after the match that does not contain any stopphrase to the qualifying section\n",
        "        if not check_stop_phrases_element(element):\n",
        "          qualifications.append(truncate_text_on_stopphrase(element))\n",
        "          break\n",
        "\n",
        "      # Execute if none of the previous conditions or patterns match a keyphrase\n",
        "      if found == False:\n",
        "        # Iterate over elements found in the BeautifulSoup object and check if the element's tag name is in the list of specified tags\n",
        "        for element in soup.find_all():\n",
        "            # Ensure the element has a string value, that the key_phrase is present in the string\n",
        "            # Verify that key_phrase is not in key_phrases_exact_match (unless it is an exact match)\n",
        "            # Confirm that none of the stop_phrases are present in the element's string\n",
        "            if element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i','u','em', 'span', 'font', 'a'] and element.string != None and key_phrase in element.string and len(element.string.split()) < 11 and ((key_phrase not in key_phrases_exact_match or key_phrase == element.string)) and all(stop_phrase not in element.string for stop_phrase in stop_phrases):\n",
        "                found = True\n",
        "                key_phrase_found = True\n",
        "                break\n",
        "            # Check if the element's tag is in the list of specified tags\n",
        "            # Check if the element's stripped text matches the key_phrase or its variations with specific suffixes\n",
        "            if element.name in ['p', 'div', 'ul', 'li'] and (element.text.strip() in [key_phrase, key_phrase + ':', key_phrase + ';', key_phrase + '-']):\n",
        "                found = True\n",
        "                key_phrase_found = True\n",
        "                break\n",
        "\n",
        "      # If keyphrase has been found, extraction of sentences which include qualification\n",
        "      if found:\n",
        "\n",
        "          # Stores qualifications temporarily\n",
        "          temporary_qualifications = []\n",
        "\n",
        "          # Find first element occurring after keyphrase\n",
        "          if element:\n",
        "            next_element = element.find_next()\n",
        "          else:\n",
        "            # Break if next element is None\n",
        "            break\n",
        "\n",
        "          # Track the number of words after key_phrase\n",
        "          word_count = 0\n",
        "\n",
        "          # Continue the loop while tag name is not in ['p', 'ul', 'li', 'ol', 'div']\n",
        "          # And either the word count is less than 60 or the next_element's tag name is 'font' or 'span'\n",
        "          while next_element and next_element.name not in ['p', 'ul', 'li', 'ol','div'] and (word_count < 60 or next_element.name == 'font' or next_element.name == 'span'):\n",
        "              # Skip None type elements\n",
        "              if next_element is None:\n",
        "                  continue\n",
        "\n",
        "              if next_element:\n",
        "                # Special case to track word count for <br> elements\n",
        "                if next_element.name in ['br'] and next_element.previous_sibling:\n",
        "\n",
        "                  # Stop extracting if one of the stopwords was dedected\n",
        "                  if check_stop_phrases_element_text(next_element.previous_sibling.text.strip()):\n",
        "                    break\n",
        "\n",
        "                  # Increase word_count by the number of words of the previous sibling element\n",
        "                  word_count += len(next_element.previous_sibling.text.split())\n",
        "\n",
        "                else:\n",
        "                  # Increase word_count by the number of words of the element\n",
        "                  word_count += len(next_element.get_text().split())\n",
        "              # Break if word_count >= 60 and no ul element within the next_element\n",
        "              if word_count >= 60 and not next_element.find('ul'):\n",
        "                break\n",
        "\n",
        "              # Find next element\n",
        "              next_element = next_element.find_next()\n",
        "\n",
        "\n",
        "          allow_br = False  # Variable to check if the <br> element should be allowed\n",
        "          allow_em = False  # Variable to check if the <em> element should be allowed\n",
        "\n",
        "\n",
        "          while next_element and (next_element.name in ['p', 'ul', 'li', 'div', 'ol'] or (next_element.name == 'br' and allow_br) or (next_element.name == 'em' and allow_em)):\n",
        "              #Tracks if p or ul section was found\n",
        "              p_ul_found = True\n",
        "\n",
        "              # # Set variables to True to continue the loop if any of the specified elements occur\n",
        "              if next_element.name in ['p', 'ul', 'li', 'div', 'ol']:\n",
        "                  allow_br = True\n",
        "                  allow_em = True\n",
        "\n",
        "              # Stops extracting if one of the stopwords has been dedected\n",
        "              if check_stop_phrases_element(next_element):\n",
        "                break\n",
        "\n",
        "              #########\n",
        "              # Lists\n",
        "              #########\n",
        "              if next_element.name in ['ul','li','ol']:\n",
        "                  # Track if ul list was found\n",
        "                  ul_list_found = True\n",
        "\n",
        "                  ###################################\n",
        "                  # Option #1: There is a valid list element\n",
        "                  ###################################\n",
        "                  # List has li-elements\n",
        "                  if next_element.find_all('li', recursive=False) != []:\n",
        "                    for li in next_element.find_all('li', recursive=False):\n",
        "                        # Checking for stopphrase and break if detected\n",
        "                        if check_stop_phrases_element(li):\n",
        "                          break\n",
        "                        # Special case that there is a second list within a list\n",
        "                        # Only valid if less than 3 sentences have been collected so far, otherwise it will be skipped\n",
        "                        if li.find('ul'):\n",
        "                          if len(set(temporary_qualifications)) < 3:\n",
        "                            qualifications.append(li.text)\n",
        "                            temporary_qualifications.append(li.text)\n",
        "                            section_found = True\n",
        "                          else:\n",
        "                            continue\n",
        "                        # Extract qualification sentences\n",
        "                        else:\n",
        "                          qualifications.append(truncate_text_on_stopphrase(li))\n",
        "                          temporary_qualifications.append(truncate_text_on_stopphrase(li))\n",
        "                          section_found = True\n",
        "\n",
        "\n",
        "                        #  Check if the current list section is concluded by checking the next element\n",
        "                        next_element_check = li.find_next()\n",
        "                        if next_element_check and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u', 'p','em', 'a']:\n",
        "                          if any(qualification not in key_phrases for qualification in temporary_qualifications) and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u', 'p','em', 'a']:\n",
        "                              break\n",
        "                  # List has no li-elements\n",
        "                  elif next_element.name in ['ul','ol']:\n",
        "                    qualifications.append(truncate_text_on_stopphrase(next_element))\n",
        "                    temporary_qualifications.append(truncate_text_on_stopphrase(next_element))\n",
        "                    section_found = True\n",
        "\n",
        "\n",
        "                  ###################################\n",
        "                  # Option #2: there is no list begining tag\n",
        "                  ###################################\n",
        "                  else:\n",
        "                    if next_element.previous_sibling:\n",
        "                      for li in next_element.previous_sibling.find_all_next('li', recursive=False):\n",
        "                        # Check for stopphrase and break if detected\n",
        "                        if check_stop_phrases_element(li):\n",
        "                          break\n",
        "\n",
        "                        # Detects <strong> elements within a <li> element containing a key_phrase and skips it\n",
        "                        if li.find('strong'):\n",
        "                            strong_element = li.find('strong')\n",
        "                            for key_phrase in key_phrases:\n",
        "                              if strong_element.string and key_phrase in strong_element.string:\n",
        "                                continue\n",
        "                            # Appen it to qualifications if no key_phrase in it\n",
        "                            qualifications.append(li.text)\n",
        "                            temporary_qualifications.append(li.text)\n",
        "                            section_found = True\n",
        "                        if li.find('ul'):\n",
        "                            continue\n",
        "                        else:\n",
        "                            # Append sentences to qualifications\n",
        "                            qualifications.append(truncate_text_on_stopphrase(li))\n",
        "                            temporary_qualifications.append(truncate_text_on_stopphrase(li))\n",
        "                            section_found = True\n",
        "\n",
        "                        # Check if all li elements has been completely extracted\n",
        "                        next_element_check = li.find_next()\n",
        "                        if next_element_check and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u', 'p','em', 'a']:\n",
        "                          if any(qualification not in key_phrases for qualification in temporary_qualifications) and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u', 'p','em', 'a']:\n",
        "                              break\n",
        "\n",
        "\n",
        "                  # Find next sibling element\n",
        "                  next_element_check = next_element.find_next_sibling()\n",
        "\n",
        "                  # Check whether the current list has been completely extracted\n",
        "                  if next_element_check and not (next_element_check.text == '' and next_element_check.name == 'p'):\n",
        "                    if next_element_check and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u','em', 'a']:\n",
        "                      if any(qualification not in key_phrases for qualification in temporary_qualifications) and next_element_check.name not in ['font','b', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','ol', 'i', 'u' ,'em', 'a']:\n",
        "                          break\n",
        "\n",
        "              ###########\n",
        "              # Sections\n",
        "              ###########\n",
        "              # Extract <p> elements which have a textual content\n",
        "              if next_element.name == 'p' and next_element.text.strip() != \"\":\n",
        "                if next_element.string == None:\n",
        "                  qualifications.append(truncate_text_on_stopphrase(next_element))\n",
        "                  section_found = True\n",
        "                else:\n",
        "                  qualifications.append(next_element.string)\n",
        "                  section_found = True\n",
        "                next_element_check = next_element.find_next_sibling()\n",
        "\n",
        "                # Check if p sections has been completely extracted\n",
        "                if next_element_check and next_element_check.name not in ['font', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong', 'p', 'b','ol', 'u','em', 'a']:\n",
        "                    break\n",
        "\n",
        "              ###############\n",
        "              # Div elements\n",
        "              ###############\n",
        "              if next_element.name == 'div':\n",
        "                # Check if there is a stop phrase within the element text\n",
        "                if not any(stop_phrase in next_element.text for stop_phrase in stop_phrases):\n",
        "                  qualifications.append(next_element.text)\n",
        "                  section_found = True\n",
        "                else:\n",
        "                  qualifications.append(truncate_text_on_stopphrase(next_element))\n",
        "                  section_found = True\n",
        "\n",
        "                # Check if div sections has been completely extracted\n",
        "                next_element_check = next_element.find_next_sibling()\n",
        "                if next_element_check and next_element_check.name not in ['font', 'ul', 'li', 'span', 'br', 'td', 'tr', 'strong','b','ol', 'div', 'u','em', 'a']:\n",
        "                    break\n",
        "\n",
        "              # Find next element\n",
        "              if next_element.find_next_sibling() is None:\n",
        "                next_element = next_element.find_next()\n",
        "              else:\n",
        "                next_element = next_element.find_next_sibling()\n",
        "\n",
        "\n",
        "          # Case no section or list element was found\n",
        "          if not p_ul_found:\n",
        "              # Case 1: Qualifications within a strong tag\n",
        "              # Find the index of the closing </strong> tag after the keyword\n",
        "              closing_tag_index = df_row.find('</strong>', df_row.find(key_phrase))\n",
        "\n",
        "              # Check if a closing tag index was found\n",
        "              if closing_tag_index != -1:\n",
        "                  # Find the index of the next opening <strong> tag\n",
        "                  opening_tag_index = df_row.find('<strong>', closing_tag_index)\n",
        "                  if opening_tag_index != -1:\n",
        "                      # Extracts the text between the two tags\n",
        "                      text_between_strong = df_row[closing_tag_index + len('<strong>'):opening_tag_index]\n",
        "\n",
        "                      # Stops extracting if one of the stopwords has been dedected\n",
        "                      if check_stop_phrases_element_text(text_between_strong):\n",
        "                        break\n",
        "\n",
        "                      else:\n",
        "                        # Add the text to qualifications\n",
        "                        qualifications.append(text_between_strong.strip())\n",
        "\n",
        "\n",
        "              # Case 2: Qualifications/Key phrase within a <b>-tag\n",
        "              # Find all <b>-tags\n",
        "              b_tags = soup.find_all('b')\n",
        "              text_between_b_tags = ''\n",
        "\n",
        "              # Iterate through all <b> tag\n",
        "              for i in range(len(b_tags)):\n",
        "                text_between_b_tags = ''\n",
        "                if key_phrase in b_tags[i].text:\n",
        "                    next_element = b_tags[i].find_next_sibling()\n",
        "                    word_count = 0\n",
        "                    # Check if the current iteration is the last index of the b_tags list\n",
        "                    if i == len(b_tags) - 1:\n",
        "                      if next_element and next_element.name == 'br' and next_element.previous_sibling:\n",
        "\n",
        "                            # Stops extracting if one of the stopwords has been dedected\n",
        "                            if check_stop_phrases_element_text(next_element.previous_sibling.text.strip()):\n",
        "                              break\n",
        "\n",
        "                            # Reset word count when encountering a <br> tag\n",
        "                            word_count = 0\n",
        "                            words = next_element.previous_sibling.text.split()\n",
        "                            word_count += len(words)\n",
        "\n",
        "                            # Filter out large paragraphs which likely to be description of the company\n",
        "                            if word_count <= 75:\n",
        "                                qualifications.append(next_element.previous_sibling.text.strip())\n",
        "                            if next_element is not None:\n",
        "                              next_element = next_element.find_next()\n",
        "\n",
        "                    # Case, qualifications are separated by <br> elements\n",
        "                    while next_element and (next_element.name == 'br'):\n",
        "\n",
        "                        # Stops extracting if one of the stopwords has been dedected\n",
        "                        if check_stop_phrases_element_text(next_element.previous_sibling.text.strip()):\n",
        "                          break\n",
        "\n",
        "                        if next_element and next_element.name == 'br' and next_element.previous_sibling:\n",
        "\n",
        "                            # Reset word count when encountering a <br> tag\n",
        "                            word_count = 0\n",
        "                            words = next_element.previous_sibling.text.split()\n",
        "                            word_count += len(words)\n",
        "\n",
        "                            # Filter out large paragraphs which likely to be description of the company\n",
        "                            if word_count <= 75:\n",
        "                              qualifications.append(next_element.previous_sibling.text.strip())\n",
        "\n",
        "                              # Handle the case of the last sentence in the qualifications section (a tag other than <br> is encountered)\n",
        "                              if next_element.find_next() and next_element.find_next().name != 'br':\n",
        "                                  pre_next_element = next_element.find_next()\n",
        "\n",
        "                                  # Stops extracting if one of the stopwords was dedected\n",
        "                                  if not any(stop_phrase in pre_next_element.find_previous().text for stop_phrase in stop_phrases):\n",
        "                                    qualifications.append(pre_next_element.find_previous().text.strip())\n",
        "\n",
        "                                  # Stops extracting if one of the stopwords was dedected\n",
        "                                  elif next_element.string != None and not any(stop_phrase_exact_match == re.sub(r'[^\\w\\s]', '', pre_next_element.find_previous().text) for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "                                    qualifications.append(pre_next_element.find_previous().text.strip())\n",
        "\n",
        "                              # Handle the case of the last sentence in the qualifications section (no tag is encountered)\n",
        "                              elif next_element.find_next() == None:\n",
        "                                filtered_html = ''.join(str(element) for element in next_element.next_siblings if element != '\\n')\n",
        "\n",
        "                                # Stops extracting if one of the stopwords was dedected\n",
        "                                if not any(stop_phrase in filtered_html for stop_phrase in stop_phrases):\n",
        "                                  qualifications.append(filtered_html)\n",
        "\n",
        "                            # Find next element\n",
        "                            if next_element is not None:\n",
        "                              next_element = next_element.find_next()\n",
        "\n",
        "              # Case Keyphrase has been found but no list or section was found\n",
        "              if found:\n",
        "                # In some cases there is a br tag within the strong tag, in this case we find the next tag\n",
        "                if element and element.name == 'strong':\n",
        "                  element = element.find_next()\n",
        "\n",
        "                # Skip the first <br> tag since the first qualification sentence comes after it\n",
        "                if element and element.name == 'br':\n",
        "                  next_element = element.find_next()\n",
        "\n",
        "                # <strong> element should only be allowed after br or span element\n",
        "                allow_strong = False\n",
        "                # Case #1, qualifications are separated by <br> elements\n",
        "                while next_element and ((next_element.name in ['br', 'span']) or (allow_strong and next_element.name in ['br', 'span', 'strong', 'b'])):\n",
        "                        allow_strong = True\n",
        "\n",
        "                        if next_element and next_element.name in ['br', 'span'] and next_element.previous_sibling:\n",
        "\n",
        "                            # Reset word count\n",
        "                            word_count = 0\n",
        "                            words = next_element.previous_sibling.text.split()\n",
        "                            word_count += len(words)\n",
        "\n",
        "                            # Stops extracting if one of the stopwords was dedected\n",
        "                            if check_stop_phrases_element_text(next_element.previous_sibling.text.strip()):\n",
        "                              break\n",
        "\n",
        "                            # Filter out large paragraphs which likely to be description of the company\n",
        "                            if word_count <= 40:\n",
        "                                qualifications.append(next_element.previous_sibling.text.strip())\n",
        "\n",
        "                                # Handle the case of the last sentence in the qualifications section\n",
        "                                if next_element.next_sibling and next_element.next_sibling.name != 'br':\n",
        "\n",
        "                                  # Stops extracting if one of the stopwords was dedected\n",
        "                                  if not any(stop_phrase in next_element.next_sibling.text for stop_phrase in stop_phrases):\n",
        "                                    qualifications.append(next_element.next_sibling.text.strip())\n",
        "\n",
        "                                  # Stops extracting if one of the stopwords was dedected\n",
        "                                  elif next_element.string != None and not any(stop_phrase_exact_match == re.sub(r'[^\\w\\s]', '', next_element.next_sibling.text.strip()) for stop_phrase_exact_match in stop_phrases_exact_match):\n",
        "                                    qualifications.append(next_element.next_sibling.text.strip())\n",
        "\n",
        "                        # Find next element\n",
        "                        if next_element is not None:\n",
        "                          next_element = next_element.find_next()\n",
        "\n",
        "                # Case #2, qualifications are within table rows\n",
        "                if soup.find('tr') is not None and key_phrase in key_phrases_without_exact_match:\n",
        "                  start_index = df_row.find(\"<tr>\", df_row.find(key_phrase))\n",
        "                  end_index = df_row.find(\"</tr>\", start_index) + len(\"</tr>\")\n",
        "\n",
        "                  next_tr = df_row[start_index:end_index]\n",
        "                  soup2 = BeautifulSoup(next_tr, 'html.parser')\n",
        "\n",
        "                  # Extract text from the HTML\n",
        "                  if soup2.get_text() and not check_stop_phrases_element(soup2):\n",
        "                    qualifications.append(soup2.get_text())\n",
        "\n",
        "                  if soup2.get_text().strip():\n",
        "                    tr_found = True\n",
        "                    key_phrase_found = True\n",
        "\n",
        "\n",
        "                # Case #3: Key_phrase is in an string element within a paragraph\n",
        "                pattern = rf'<strong>{re.escape(key_phrase)}:</strong>(.*?)</p>'\n",
        "                match = re.search(pattern, df_row, re.DOTALL)\n",
        "                if match:\n",
        "                    qualifications.append(match.group(1).strip())\n",
        "\n",
        "          # Section has been found\n",
        "          section_found = True\n",
        "\n",
        "    # Case no section and no keyphrase has been found\n",
        "    if section_found == False:\n",
        "        # Case keyphrase within an <ul>-tag/<li>-tag\n",
        "        ul_tags = soup.find_all('ul')\n",
        "        for ul_tag in ul_tags:\n",
        "          if key_phrase in ul_tag.text:\n",
        "              print(ul_tag.text)\n",
        "              li_tags = ul_tag.find_all('li')\n",
        "              for li_tag in li_tags:\n",
        "                if key_phrase in li_tag.text:\n",
        "                  next_li_tags = li_tag.find_all_next('li')\n",
        "                  for next_li_tag in next_li_tags:\n",
        "                    if key_phrase not in next_li_tag.text:\n",
        "                      qualifications.append(next_li_tag.text.strip())\n",
        "                  break\n",
        "\n",
        "    # Remove remaining html tags\n",
        "    qualifications = [BeautifulSoup(text, \"html.parser\").get_text() for text in qualifications]\n",
        "\n",
        "    # Remove special characters\n",
        "    qualifications = [text.replace(\"<\", \"\").replace(\">\", \"\").replace(\"•\", \"\") for text in qualifications]\n",
        "\n",
        "    # Remove multiple spaces and line breaks\n",
        "    qualifications = [re.sub(r'\\s+', ' ', text) for text in qualifications]\n",
        "\n",
        "    # Remove duplicates #1\n",
        "    qualifications = list(set(qualifications))\n",
        "\n",
        "    # Remove leading/trailing whitespace and filter out empty qualifications\n",
        "    qualifications = [qualification.strip() for qualification in qualifications if qualification.strip()]\n",
        "    qualifications = list(filter(None, qualifications))\n",
        "\n",
        "    # Filter qualifications based on alphabetical characters and key phrases\n",
        "    qualifications = filter_and_clean_qualifications(qualifications)\n",
        "\n",
        "    # Remove list items that only contain stopwords\n",
        "    qualifications = [item for item in qualifications if not any(word == item for word in stop_words)]\n",
        "\n",
        "    # Remove duplicates #2\n",
        "    qualifications = list(set(qualifications))\n",
        "\n",
        "    # Exclude sentences that are already contained in other paragraphs\n",
        "    qualifications = filter_duplicates(qualifications)\n",
        "\n",
        "\n",
        "    if len(qualifications) == 0 and key_phrase_found:\n",
        "      print('Skills can not be detected!')\n",
        "      return('Skills can not be detected!')\n",
        "    elif len(qualifications) == 0 and not key_phrase_found:\n",
        "      print('Keyphrase can not be detected!')\n",
        "      return('Skills can not be detected!')\n",
        "    else:\n",
        "      print(qualifications)\n",
        "      return qualifications"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Extraction of qualification section"
      ],
      "metadata": {
        "id": "mPVgo0Mw7YSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Extraction of qualification for whole dataset"
      ],
      "metadata": {
        "id": "rYLxFb_tyQb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_data['qualifications'] = job_data.apply(lambda row: (print(row['id']), extract_qualification_section(row['rawDescriptionTranslated']))[1], axis=1)"
      ],
      "metadata": {
        "id": "b9Vtgt59DZRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Extraction method for one specific job ad (for development purposes and accuracy only)"
      ],
      "metadata": {
        "id": "_B3cs21g72lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define text for single extraction\n",
        "j = 0\n",
        "text = \"\"\"\"\"\""
      ],
      "metadata": {
        "id": "vEQth70LE8Hk"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract single skill section\n",
        "'''\n",
        "j = 0\n",
        "if extract_qualification_section(text) is not None:\n",
        "  for i in extract_qualification_section(text):\n",
        "    j = j + 1\n",
        "    print(j)\n",
        "    print(i)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9aKmX98nzuVW",
        "outputId": "5178af44-c31c-424d-b3b6-f20db72c9a82"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nj = 0\\nif extract_qualification_section(text) is not None:\\n  for i in extract_qualification_section(text):\\n    j = j + 1\\n    print(j)\\n    print(i)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 Preparing data for export"
      ],
      "metadata": {
        "id": "CkYyDAN7zHsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list to string\n",
        "job_data['qualifications'] = job_data['qualifications'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "\n",
        "# Filter for job ads where qualifications were detected\n",
        "job_data = job_data[job_data['qualifications'] != 'Skills can not be detected!']"
      ],
      "metadata": {
        "id": "wYwQuwb1xrsZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Export"
      ],
      "metadata": {
        "id": "30eSmp_88XGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Excel export of dataset with extracted skill-section"
      ],
      "metadata": {
        "id": "N_PhEbCjNLc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export dataset detected with skill sections\n",
        "job_data.to_excel('job_data_preprocessed_extracted_qualifications.xlsx', index=False)"
      ],
      "metadata": {
        "id": "9KVSo0Y8zDXg"
      },
      "execution_count": 74,
      "outputs": []
    }
  ]
}